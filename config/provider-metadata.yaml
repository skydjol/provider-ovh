name: ovh/ovh
resources:
    cloud_project_user_s3_credential:
        subCategory: ""
        name: cloud_project_user_s3_credential
        title: ""
        argumentDocs:
            access_key_id: '- the Access Key ID'
            secret_access_key: '- (Sensitive) the Secret Access Key'
            service_name: |-
                - (Required) The ID of the public cloud project. If omitted,
                the OVH_CLOUD_PROJECT_SERVICE environment variable is used.
            user_id: '- (Required) The ID of a public cloud project''s user.'
        importStatements: []
    dbaas_logs_graylog_output_stream:
        subCategory: ""
        name: dbaas_logs_graylog_output_stream
        title: ""
        argumentDocs:
            can_alert: '- Indicates if the current user can create alert on the stream'
            cold_storage_compression: '- Cold storage compression method. One of "LZMA", "GZIP", "DEFLATED", "ZSTD"'
            cold_storage_content: '- ColdStorage content. One of "ALL", "GLEF", "PLAIN"'
            cold_storage_enabled: '- Is Cold storage enabled?'
            cold_storage_notify_enabled: '- Notify on new Cold storage archive'
            cold_storage_retention: '- Cold storage retention in year'
            cold_storage_target: '- ColdStorage destination. One of "PCA", "PCS"'
            created_at: '- Stream creation'
            description: '- (Required) Stream description'
            indexing_enabled: '- Enable ES indexing'
            indexing_max_size: '- Maximum indexing size (in GB)'
            indexing_notify_enabled: '- If set, notify when size is near 80, 90 or 100 % of the maximum configured setting'
            is_editable: '- Indicates if you are allowed to edit entry'
            is_shareable: '- Indicates if you are allowed to share entry'
            nb_alert_condition: '- Number of alert condition'
            nb_archive: '- Number of coldstored archivesr'
            parent_stream_id: '- Parent stream ID'
            pause_indexing_on_max_size: '- If set, pause indexing when maximum size is reach'
            retention_id: '- Retention ID'
            service_name: '- (Required) The service name'
            stream_id: '- Stream ID'
            title: '- (Required) Stream description'
            updated_at: '- Stream last updater'
            web_socket_enabled: '- Enable Websocket'
        importStatements: []
    ovh_cloud_project:
        subCategory: ""
        name: ovh_cloud_project
        title: ""
        examples:
            - name: my_cloud_project
              manifest: |-
                {
                  "description": "my cloud project",
                  "ovh_subsidiary": "${data.ovh_order_cart.mycart.ovh_subsidiary}",
                  "plan": [
                    {
                      "duration": "${data.ovh_order_cart_product_plan.cloud.selected_price.0.duration}",
                      "plan_code": "${data.ovh_order_cart_product_plan.cloud.plan_code}",
                      "pricing_mode": "${data.ovh_order_cart_product_plan.cloud.selected_price.0.pricing_mode}"
                    }
                  ]
                }
              references:
                ovh_subsidiary: data.ovh_order_cart.mycart.ovh_subsidiary
                plan.duration: data.ovh_order_cart_product_plan.cloud.selected_price.0.duration
                plan.plan_code: data.ovh_order_cart_product_plan.cloud.plan_code
                plan.pricing_mode: data.ovh_order_cart_product_plan.cloud.selected_price.0.pricing_mode
        argumentDocs:
            access: '- project access right for the identity that trigger the terraform script.'
            catalog_name: '- Catalog name'
            configuration: '- (Optional) Representation of a configuration item for personalizing product'
            date: '- date'
            description: '- A description associated with the user.'
            details: '- Information about a Bill entry'
            domain: '- expiration date'
            duration: '- (Required) duration'
            expiration_date: '- expiration date'
            label: '- (Required) Identifier of the resource'
            order: '- Details about the order that was used to create the public cloud project'
            order_detail_id: '- order detail id'
            order_id: '- order id, the same as the id'
            ovh_subsidiary: '- (Required) OVHcloud Subsidiary'
            plan: '- (Required) Product Plan to order'
            plan_code: '- (Required) Plan code'
            plan_option: '- (Optional) Product Plan to order'
            pricing_mode: '- (Required) Pricing model identifier'
            project_id: '- openstack project id'
            project_name: '- openstack project name'
            quantity: '- quantity'
            status: '- project status'
            value: '- (Required) Path to the resource in API.OVH.COM'
        importStatements: []
    ovh_cloud_project_containerregistry:
        subCategory: ""
        name: ovh_cloud_project_containerregistry
        title: ""
        examples:
            - name: reg
              manifest: |-
                {
                  "name": "mydockerregistry",
                  "plan_id": "${data.ovh_cloud_project_capabilities_containerregistry_filter.regcap.id}",
                  "region": "${data.ovh_cloud_project_capabilities_containerregistry_filter.regcap.region}",
                  "service_name": "${data.ovh_cloud_project_capabilities_containerregistry_filter.regcap.service_name}"
                }
              references:
                plan_id: data.ovh_cloud_project_capabilities_containerregistry_filter.regcap.id
                region: data.ovh_cloud_project_capabilities_containerregistry_filter.regcap.region
                service_name: data.ovh_cloud_project_capabilities_containerregistry_filter.regcap.service_name
        argumentDocs:
            code: '- Plan code from the catalog'
            created_at: '- Registry creation date'
            features: '- Features of the plan'
            id: '- Registry ID'
            image_storage: '- Docker image storage limits in bytes'
            name: '- Registry name'
            parallel_request: '- Parallel requests on Docker image API (/v2 Docker registry API)'
            plan: '-  Plan of the registry'
            plan_id: '- Plan ID of the registry'
            project_id: '- Project ID of your registry'
            region: '- Region of the registry'
            registry_limits: '- Container registry limits'
            service_name: |-
                - The id of the public cloud project. If omitted,
                the OVH_CLOUD_PROJECT_SERVICE environment variable is used.
            size: '- Current size of the registry (bytes)'
            status: '- Registry status'
            updated_at: '- Plan last update date'
            url: '- Access url of the registry'
            version: '- Version of your registry'
            vulnerability: '- Vulnerability scanning'
        importStatements: []
    ovh_cloud_project_containerregistry_user:
        subCategory: ""
        name: ovh_cloud_project_containerregistry_user
        title: ""
        examples:
            - name: user
              manifest: |-
                {
                  "email": "foo@bar.com",
                  "login": "foobar",
                  "registry_id": "${ovh_cloud_project_containerregistry.registry.id}",
                  "service_name": "${ovh_cloud_project_containerregistry.registry.service_name}"
                }
              references:
                registry_id: ovh_cloud_project_containerregistry.registry.id
                service_name: ovh_cloud_project_containerregistry.registry.service_name
        argumentDocs:
            email: '- User email'
            id: '- User ID'
            password: '- (Sensitive) User password'
            registry_id: '- Registry ID'
            service_name: |-
                - The id of the public cloud project. If omitted,
                the OVH_CLOUD_PROJECT_SERVICE environment variable is used.
            user: '- User name'
        importStatements: []
    ovh_cloud_project_database:
        subCategory: ""
        name: ovh_cloud_project_database
        title: ""
        examples:
            - name: cassandradb
              manifest: |-
                {
                  "description": "my-first-cassandra",
                  "engine": "cassandra",
                  "flavor": "db1-4",
                  "nodes": [
                    {
                      "region": "BHS"
                    },
                    {
                      "region": "BHS"
                    },
                    {
                      "region": "BHS"
                    }
                  ],
                  "plan": "essential",
                  "service_name": "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx",
                  "version": "4.0"
                }
            - name: kafkadb
              manifest: |-
                {
                  "description": "my-first-kafka",
                  "engine": "kafka",
                  "flavor": "db1-4",
                  "kafka_rest_api": true,
                  "nodes": [
                    {
                      "region": "DE"
                    },
                    {
                      "region": "DE"
                    },
                    {
                      "region": "DE"
                    }
                  ],
                  "plan": "business",
                  "service_name": "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx",
                  "version": "3.1"
                }
            - name: m3db
              manifest: |-
                {
                  "description": "my-first-m3db",
                  "engine": "m3db",
                  "flavor": "db1-7",
                  "nodes": [
                    {
                      "region": "BHS"
                    }
                  ],
                  "plan": "essential",
                  "service_name": "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx",
                  "version": "1.2"
                }
            - name: mongodb
              manifest: |-
                {
                  "description": "my-first-mongodb",
                  "engine": "mongodb",
                  "flavor": "db1-2",
                  "nodes": [
                    {
                      "region": "GRA"
                    }
                  ],
                  "plan": "essential",
                  "service_name": "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx",
                  "version": "5.0"
                }
            - name: mysqldb
              manifest: |-
                {
                  "advanced_configuration": {
                    "mysql.sql_mode": "ANSI,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION,NO_ZERO_DATE,NO_ZERO_IN_DATE,STRICT_ALL_TABLES",
                    "mysql.sql_require_primary_key": "true"
                  },
                  "description": "my-first-mysql",
                  "engine": "mysql",
                  "flavor": "db1-4",
                  "nodes": [
                    {
                      "region": "SBG"
                    }
                  ],
                  "plan": "essential",
                  "service_name": "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx",
                  "version": "8"
                }
            - name: opensearchdb
              manifest: |-
                {
                  "description": "my-first-opensearch",
                  "engine": "opensearch",
                  "flavor": "db1-4",
                  "nodes": [
                    {
                      "region": "UK"
                    }
                  ],
                  "opensearch_acls_enabled": true,
                  "plan": "essential",
                  "service_name": "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx",
                  "version": "1"
                }
            - name: pgsqldb
              manifest: |-
                {
                  "description": "my-first-postgresql",
                  "engine": "postgresql",
                  "flavor": "db1-4",
                  "nodes": [
                    {
                      "region": "WAW"
                    }
                  ],
                  "plan": "essential",
                  "service_name": "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx",
                  "version": "14"
                }
            - name: redisdb
              manifest: |-
                {
                  "description": "my-first-redis",
                  "engine": "redis",
                  "flavor": "db1-4",
                  "nodes": [
                    {
                      "region": "BHS"
                    }
                  ],
                  "plan": "essential",
                  "service_name": "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx",
                  "version": "6.2"
                }
            - name: grafana
              manifest: |-
                {
                  "description": "my-first-grafana",
                  "engine": "grafana",
                  "flavor": "db1-4",
                  "nodes": [
                    {
                      "region": "GRA"
                    }
                  ],
                  "plan": "essential",
                  "service_name": "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx",
                  "version": "9.1"
                }
            - name: postgresql
              manifest: |-
                {
                  "description": "my-first-postgresql",
                  "engine": "postgresql",
                  "flavor": "db1-15",
                  "nodes": [
                    {
                      "region": "GRA"
                    },
                    {
                      "region": "GRA"
                    }
                  ],
                  "plan": "business",
                  "service_name": "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx",
                  "version": "14"
                }
            - name: mongodb
              manifest: |-
                {
                  "description": "my-first-mongodb",
                  "engine": "mongodb",
                  "flavor": "db1-30",
                  "nodes": [
                    {
                      "network_id": "XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX",
                      "region": "SBG",
                      "subnet_id": "XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX"
                    },
                    {
                      "network_id": "XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX",
                      "region": "SBG",
                      "subnet_id": "XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX"
                    },
                    {
                      "network_id": "XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX",
                      "region": "SBG",
                      "subnet_id": "XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX"
                    }
                  ],
                  "plan": "enterprise",
                  "service_name": "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx",
                  "version": "5.0"
                }
            - name: db
              manifest: |-
                {
                  "timeouts": [
                    {
                      "create": "1h",
                      "delete": "50s",
                      "update": "45m"
                    }
                  ]
                }
        argumentDocs:
            advanced_configuration: '-  (Optional) Advanced configuration key / value.'
            backup_time: '- Time on which backups start every day.'
            component: '- Type of component the URI relates to.'
            create: '- (Default 20m)'
            created_at: '- Date of the creation of the cluster.'
            delete: '- (Default 20m)'
            description: '- (Optional) Small description of the database service.'
            disk_size: '-  (Optional) The disk size (in GB) of the database service.'
            disk_type: '-  Defines the disk type of the database service.'
            domain: '- Domain of the cluster.'
            endpoints: '- List of all endpoints objects of the service.'
            engine: |-
                - (Required, Forces new resource) The database engine you want to deploy. To get a full list of available engine visit.
                public documentation.
            flavor: |-
                -  (Required) A valid OVHcloud public cloud database flavor name in which the nodes will be started.
                Ex: "db1-7". Changing this value upgrade the nodes with the new flavor.
                You can find the list of flavor names: https://www.ovhcloud.com/fr/public-cloud/prices/
            id: '- Public Cloud Database Service ID'
            kafka_rest_api: '-  (Optional) Defines whether the REST API is enabled on a kafka cluster'
            maintenance_time: '- Time on which maintenances can start every day.'
            network_id: '- (Optional, Forces new resource) Private network id in which the node should be deployed. It''s the regional openstackId of the private network'
            network_type: '- Type of network of the cluster.'
            nodes: |-
                - (Required, Minimum Items: 1) List of nodes object.
                Multi region cluster are not yet available, all node should be identical.
            opensearch_acls_enabled: '-  (Optional) Defines whether the ACLs are enabled on an OpenSearch cluster'
            path: '- Path of the endpoint.'
            plan: |-
                - (Required) Plan of the cluster.
                Enum: "essential", "business", "enterprise".
            port: '- Connection port for the endpoint.'
            region: |-
                - (Required, Forces new resource) Public cloud region in which the node should be deployed.
                Ex: "GRA'.
            scheme: '- Scheme used to generate the URI.'
            service_name: |-
                - (Required, Forces new resource) The id of the public cloud project. If omitted,
                the OVH_CLOUD_PROJECT_SERVICE environment variable is used.
            ssl: '- Defines whether the endpoint uses SSL.'
            ssl_mode: '- SSL mode used to connect to the service if the SSL is enabled.'
            status: '- Current status of the cluster.'
            subnet_id: '- (Optional, Forces new resource) Private subnet ID in which the node is.'
            update: '- (Default 40m)'
            uri: '- URI of the endpoint.'
            version: '- (Required) The version of the engine in which the service should be deployed'
        importStatements: []
    ovh_cloud_project_database_database:
        subCategory: ""
        name: ovh_cloud_project_database_database
        title: ""
        examples:
            - name: database
              manifest: |-
                {
                  "cluster_id": "${data.ovh_cloud_project_database.db.id}",
                  "engine": "${data.ovh_cloud_project_database.db.engine}",
                  "name": "mydatabase",
                  "service_name": "${data.ovh_cloud_project_database.db.service_name}"
                }
              references:
                cluster_id: data.ovh_cloud_project_database.db.id
                engine: data.ovh_cloud_project_database.db.engine
                service_name: data.ovh_cloud_project_database.db.service_name
            - name: database
              manifest: |-
                {
                  "timeouts": [
                    {
                      "create": "1h",
                      "delete": "45m"
                    }
                  ]
                }
        argumentDocs:
            cluster_id: '- (Required, Forces new resource) Cluster ID.'
            create: '- (Default 20m)'
            default: '- Defines if the database has been created by default.'
            delete: '- (Default 20m)'
            engine: |-
                - (Required, Forces new resource) The engine of the database cluster you want to add. You can find the complete list of available engine in the public documentation.
                Available engines:
            id: '- ID of the database.'
            name: '- (Required, Forces new resource) Name of the database.'
            service_name: |-
                - (Required, Forces new resource) The id of the public cloud project. If omitted,
                the OVH_CLOUD_PROJECT_SERVICE environment variable is used.
        importStatements: []
    ovh_cloud_project_database_integration:
        subCategory: ""
        name: ovh_cloud_project_database_integration
        title: ""
        examples:
            - name: integration
              manifest: |-
                {
                  "cluster_id": "${data.ovh_cloud_project_database.dbpostgresql.id}",
                  "destination_service_id": "${data.ovh_cloud_project_database.dbopensearch.id}",
                  "engine": "${data.ovh_cloud_project_database.dbpostgresql.engine}",
                  "service_name": "${data.ovh_cloud_project_database.dbpostgresql.service_name}",
                  "source_service_id": "${data.ovh_cloud_project_database.dbpostgresql.id}",
                  "type": "opensearchLogs"
                }
              references:
                cluster_id: data.ovh_cloud_project_database.dbpostgresql.id
                destination_service_id: data.ovh_cloud_project_database.dbopensearch.id
                engine: data.ovh_cloud_project_database.dbpostgresql.engine
                service_name: data.ovh_cloud_project_database.dbpostgresql.service_name
                source_service_id: data.ovh_cloud_project_database.dbpostgresql.id
        argumentDocs:
            cluster_id: '- (Required, Forces new resource) Cluster ID.'
            create: '- (Default 20m)'
            delete: '- (Default 20m)'
            destination_service_id: '- (Required, Forces new resource) ID of the destination service.'
            engine: |-
                - (Required, Forces new resource) The engine of the database cluster you want to add. You can find the complete list of available engine in the public documentation.
                All engines available exept mongodb.
            id: '- - ID of the integration.'
            parameters: '- (Optional, Forces new resource) Parameters for the integration.'
            service_name: |-
                - (Required, Forces new resource) The id of the public cloud project. If omitted,
                the OVH_CLOUD_PROJECT_SERVICE environment variable is used.
            source_service_id: '- (Required, Forces new resource) ID of the source service.'
            status: '- Current status of the integration.'
            type: |-
                - (Optional, Forces new resource) Type of the integration.
                Available types:
            update: '- (Default 20m)'
        importStatements: []
    ovh_cloud_project_database_ip_restriction:
        subCategory: ""
        name: ovh_cloud_project_database_ip_restriction
        title: ""
        examples:
            - name: iprestriction
              manifest: |-
                {
                  "cluster_id": "${data.ovh_cloud_project_database.db.id}",
                  "engine": "${data.ovh_cloud_project_database.db.engine}",
                  "ip": "178.97.6.0/24",
                  "service_name": "${data.ovh_cloud_project_database.db.service_name}"
                }
              references:
                cluster_id: data.ovh_cloud_project_database.db.id
                engine: data.ovh_cloud_project_database.db.engine
                service_name: data.ovh_cloud_project_database.db.service_name
            - name: iprestriction
              manifest: |-
                {
                  "timeouts": [
                    {
                      "create": "1h",
                      "delete": "50s",
                      "update": "45m"
                    }
                  ]
                }
        argumentDocs:
            cluster_id: '- (Required, Forces new resource) Cluster ID.'
            create: '- (Default 20m)'
            delete: '- (Default 20m)'
            description: '- (Optional) Description of the IP restriction.'
            engine: |-
                - (Required, Forces new resource) The engine of the database cluster you want to add an IP restriction. To get a full list of available engine visit.
                public documentation.
            ip: '- (Required, Forces new resource) Authorized IP.'
            service_name: |-
                - (Required, Forces new resource) The id of the public cloud project. If omitted,
                the OVH_CLOUD_PROJECT_SERVICE environment variable is used.
            status: '- Current status of the IP restriction.'
            update: '- (Default 20m)'
        importStatements: []
    ovh_cloud_project_database_kafka_acl:
        subCategory: ""
        name: ovh_cloud_project_database_kafka_acl
        title: ""
        examples:
            - name: acl
              manifest: |-
                {
                  "cluster_id": "${data.ovh_cloud_project_database.kafka.id}",
                  "permission": "read",
                  "service_name": "${data.ovh_cloud_project_database.kafka.service_name}",
                  "topic": "mytopic",
                  "username": "johndoe"
                }
              references:
                cluster_id: data.ovh_cloud_project_database.kafka.id
                service_name: data.ovh_cloud_project_database.kafka.service_name
            - name: acl
              manifest: |-
                {
                  "timeouts": [
                    {
                      "create": "1h",
                      "delete": "45m"
                    }
                  ]
                }
        argumentDocs:
            cluster_id: '- (Required, Forces new resource) Cluster ID.'
            create: '- (Default 20m)'
            delete: '- (Default 20m)'
            id: '- ID of the ACL.'
            permission: |-
                - (Required, Forces new resource) Permission to give to this username on this topic.
                Available permissions:
            service_name: |-
                - (Required, Forces new resource) The id of the public cloud project. If omitted,
                the OVH_CLOUD_PROJECT_SERVICE environment variable is used.
            topic: '- (Required, Forces new resource) Topic affected by this ACL.'
            username: '- (Required, Forces new resource) Username affected by this ACL.'
        importStatements: []
    ovh_cloud_project_database_kafka_topic:
        subCategory: ""
        name: ovh_cloud_project_database_kafka_topic
        title: ""
        examples:
            - name: topic
              manifest: |-
                {
                  "cluster_id": "${data.ovh_cloud_project_database.kafka.id}",
                  "min_insync_replicas": 1,
                  "name": "mytopic",
                  "partitions": 3,
                  "replication": 2,
                  "retention_bytes": 4,
                  "retention_hours": 5,
                  "service_name": "${data.ovh_cloud_project_database.kafka.service_name}"
                }
              references:
                cluster_id: data.ovh_cloud_project_database.kafka.id
                service_name: data.ovh_cloud_project_database.kafka.service_name
            - name: topic
              manifest: |-
                {
                  "timeouts": [
                    {
                      "create": "1h",
                      "delete": "45m"
                    }
                  ]
                }
        argumentDocs:
            cluster_id: '- (Required, Forces new resource) Cluster ID.'
            create: '- (Default 20m)'
            delete: '- (Default 20m)'
            id: '- ID of the topic.'
            min_insync_replicas: '- (Optional, Forces new resource) Minimum insync replica accepted for this topic. Should be superior to 0'
            name: '- (Required, Forces new resource) Name of the topic. No spaces allowed.'
            partitions: '- (Optional, Forces new resource) Number of partitions for this topic. Should be superior to 0'
            replication: '- (Optional, Forces new resource) Number of replication for this topic. Should be superior to 1'
            retention_bytes: '- (Optional, Forces new resource) Number of bytes for the retention of the data for this topic. Inferior to 0 means unlimited'
            retention_hours: '- (Optional, Forces new resource) Number of hours for the retention of the data for this topic. Should be superior to -2. Inferior to 0 means unlimited'
            service_name: |-
                - (Required, Forces new resource) The id of the public cloud project. If omitted,
                the OVH_CLOUD_PROJECT_SERVICE environment variable is used.
        importStatements: []
    ovh_cloud_project_database_m3db_namespace:
        subCategory: ""
        name: ovh_cloud_project_database_m3db_namespace
        title: ""
        examples:
            - name: namespace
              manifest: |-
                {
                  "cluster_id": "${data.ovh_cloud_project_database.m3db.id}",
                  "name": "mynamespace",
                  "resolution": "P2D",
                  "retention_period_duration": "PT48H",
                  "service_name": "${data.ovh_cloud_project_database.m3db.service_name}"
                }
              references:
                cluster_id: data.ovh_cloud_project_database.m3db.id
                service_name: data.ovh_cloud_project_database.m3db.service_name
            - name: namespace
              manifest: |-
                {
                  "timeouts": [
                    {
                      "create": "1h",
                      "delete": "50s",
                      "update": "45m"
                    }
                  ]
                }
        argumentDocs:
            cluster_id: '- (Required, Forces new resource) Cluster ID.'
            create: '- (Default 20m)'
            delete: '- (Default 20m)'
            id: '- ID of the namespace.'
            name: '- (Required, Forces new resource) Name of the namespace.'
            resolution: '- (Optional) Resolution for an aggregated namespace. Should follow Rfc3339 e.g P2D, PT48H.'
            retention_block_data_expiration_duration: '- (Optional) Controls how long we wait before expiring stale data. Should follow Rfc3339 e.g P2D, PT48H.'
            retention_block_size_duration: '- (Optional) Controls how long to keep a block in memory before flushing to a fileset on disk. Should follow Rfc3339 e.g P2D, PT48H.'
            retention_buffer_future_duration: '- (Optional) Controls how far into the future writes to the namespace will be accepted. Should follow Rfc3339 e.g P2D, PT48H.'
            retention_buffer_past_duration: '- (Optional) Controls how far into the past writes to the namespace will be accepted. Should follow Rfc3339 e.g P2D, PT48H.'
            retention_period_duration: '- (Required) Controls the duration of time that M3DB will retain data for the namespace. Should follow Rfc3339 e.g P2D, PT48H.'
            service_name: |-
                - (Required, Forces new resource) The id of the public cloud project. If omitted,
                the OVH_CLOUD_PROJECT_SERVICE environment variable is used.
            snapshot_enabled: '- (Optional) Defines whether M3DB will create snapshot files for this namespace.'
            type: '- Type of namespace.'
            update: '- (Default 20m)'
            writes_to_commit_log_enabled: '- (Optional) Defines whether M3DB will include writes to this namespace in the commit log.'
        importStatements: []
    ovh_cloud_project_database_m3db_user:
        subCategory: ""
        name: ovh_cloud_project_database_m3db_user
        title: ""
        examples:
            - name: user
              manifest: |-
                {
                  "cluster_id": "${data.ovh_cloud_project_database.m3db.id}",
                  "group": "mygroup",
                  "name": "johndoe",
                  "service_name": "${data.ovh_cloud_project_database.m3db.service_name}"
                }
              references:
                cluster_id: data.ovh_cloud_project_database.m3db.id
                service_name: data.ovh_cloud_project_database.m3db.service_name
            - name: user
              manifest: |-
                {
                  "cluster_id": "${data.ovh_cloud_project_database.m3db.id}",
                  "group": "mygroup",
                  "name": "johndoe",
                  "password_reset": "reset1",
                  "service_name": "${data.ovh_cloud_project_database.m3db.service_name}"
                }
              references:
                cluster_id: data.ovh_cloud_project_database.m3db.id
                service_name: data.ovh_cloud_project_database.m3db.service_name
            - name: user
              manifest: |-
                {
                  "timeouts": [
                    {
                      "create": "1h",
                      "delete": "50s",
                      "update": "45m"
                    }
                  ]
                }
        argumentDocs:
            cluster_id: '- (Required, Forces new resource) Cluster ID.'
            create: '- (Default 20m)'
            created_at: '- Date of the creation of the user.'
            delete: '- (Default 20m)'
            group: '- (Optional) Group of the user:'
            id: '- ID of the user.'
            name: '- (Required, Forces new resource) Name of the user. A user named "avnadmin" is map with already created admin user instead of create a new user.'
            password: '- (Sensitive) Password of the user.'
            password_reset: '- (Optional) Arbitrary string to change to trigger a password update. Use the terraform refresh command after executing terraform apply to update the output with the new password.'
            service_name: |-
                - (Required, Forces new resource) The id of the public cloud project. If omitted,
                the OVH_CLOUD_PROJECT_SERVICE environment variable is used.
            status: '- Current status of the user.'
            update: '- (Default 20m)'
        importStatements: []
    ovh_cloud_project_database_mongodb_user:
        subCategory: ""
        name: ovh_cloud_project_database_mongodb_user
        title: ""
        examples:
            - name: user
              manifest: |-
                {
                  "cluster_id": "${data.ovh_cloud_project_database.mongodb.id}",
                  "name": "johndoe",
                  "roles": [
                    "backup",
                    "readAnyDatabase"
                  ],
                  "service_name": "${data.ovh_cloud_project_database.mongodb.service_name}"
                }
              references:
                cluster_id: data.ovh_cloud_project_database.mongodb.id
                service_name: data.ovh_cloud_project_database.mongodb.service_name
            - name: user
              manifest: |-
                {
                  "cluster_id": "${data.ovh_cloud_project_database.mongodb.id}",
                  "name": "johndoe",
                  "password_reset": "reset1",
                  "roles": [
                    "backup",
                    "readAnyDatabase"
                  ],
                  "service_name": "${data.ovh_cloud_project_database.mongodb.service_name}"
                }
              references:
                cluster_id: data.ovh_cloud_project_database.mongodb.id
                service_name: data.ovh_cloud_project_database.mongodb.service_name
            - name: user
              manifest: |-
                {
                  "timeouts": [
                    {
                      "create": "1h",
                      "delete": "50s",
                      "update": "45m"
                    }
                  ]
                }
        argumentDocs:
            cluster_id: '- (Required, Forces new resource) Cluster ID.'
            create: '- (Default 20m)'
            created_at: '- Date of the creation of the user.'
            delete: '- (Default 20m)'
            id: '- ID of the user.'
            name: '- (Required, Forces new resource) Name of the user.'
            password: '- (Sensitive) Password of the user.'
            password_reset: '- (Optional) Arbitrary string to change to trigger a password update. Use the terraform refresh command after executing terraform apply to update the output with the new password.'
            roles: |-
                - (Optional: if omit, default role) Roles the user belongs to.
                Available roles:
            service_name: |-
                - (Required, Forces new resource) The id of the public cloud project. If omitted,
                the OVH_CLOUD_PROJECT_SERVICE environment variable is used.
            status: '- Current status of the user.'
            update: '- (Default 20m)'
        importStatements: []
    ovh_cloud_project_database_opensearch_pattern:
        subCategory: ""
        name: ovh_cloud_project_database_opensearch_pattern
        title: ""
        examples:
            - name: pattern
              manifest: |-
                {
                  "cluster_id": "${data.ovh_cloud_project_database.opensearch.id}",
                  "max_index_count": 2,
                  "pattern": "logs_*",
                  "service_name": "${data.ovh_cloud_project_database.opensearch.service_name}"
                }
              references:
                cluster_id: data.ovh_cloud_project_database.opensearch.id
                service_name: data.ovh_cloud_project_database.opensearch.service_name
            - name: pattern
              manifest: |-
                {
                  "timeouts": [
                    {
                      "create": "1h",
                      "delete": "45m"
                    }
                  ]
                }
        argumentDocs:
            cluster_id: '- (Required, Forces new resource) Cluster ID.'
            create: '- (Default 20m)'
            delete: '- (Default 20m)'
            id: '- ID of the pattern.'
            max_index_count: '- (Optional, Forces new resource) Maximum number of index for this pattern.'
            pattern: '- (Required, Forces new resource) Pattern format.'
            service_name: |-
                - (Required, Forces new resource) The id of the public cloud project. If omitted,
                the OVH_CLOUD_PROJECT_SERVICE environment variable is used.
        importStatements: []
    ovh_cloud_project_database_opensearch_user:
        subCategory: ""
        name: ovh_cloud_project_database_opensearch_user
        title: ""
        examples:
            - name: user
              manifest: |-
                {
                  "acls": [
                    {
                      "pattern": "logs_*",
                      "permission": "read"
                    },
                    {
                      "pattern": "data_*",
                      "permission": "deny"
                    }
                  ],
                  "cluster_id": "${data.ovh_cloud_project_database.opensearch.id}",
                  "name": "johndoe",
                  "service_name": "${data.ovh_cloud_project_database.opensearch.service_name}"
                }
              references:
                cluster_id: data.ovh_cloud_project_database.opensearch.id
                service_name: data.ovh_cloud_project_database.opensearch.service_name
            - name: user
              manifest: |-
                {
                  "acls": [
                    {
                      "pattern": "logs_*",
                      "permission": "read"
                    },
                    {
                      "pattern": "data_*",
                      "permission": "deny"
                    }
                  ],
                  "cluster_id": "${data.ovh_cloud_project_database.opensearch.id}",
                  "name": "johndoe",
                  "password_reset": "reset1",
                  "service_name": "${data.ovh_cloud_project_database.opensearch.service_name}"
                }
              references:
                cluster_id: data.ovh_cloud_project_database.opensearch.id
                service_name: data.ovh_cloud_project_database.opensearch.service_name
            - name: user
              manifest: |-
                {
                  "timeouts": [
                    {
                      "create": "1h",
                      "delete": "50s",
                      "update": "45m"
                    }
                  ]
                }
        argumentDocs:
            acls: '- (Optional) Acls of the user.'
            cluster_id: '- (Required, Forces new resource) Cluster ID.'
            create: '- (Default 20m)'
            created_at: '- Date of the creation of the user.'
            delete: '- (Default 20m)'
            id: '- ID of the user.'
            name: '- (Required, Forces new resource) Username affected by this acl. A user named "avnadmin" is map with already created admin user and reset his password instead of create a new user.'
            password: '- (Sensitive) Password of the user.'
            password_reset: '- (Optional) Arbitrary string to change to trigger a password update. Use the terraform refresh command after executing terraform apply to update the output with the new password.'
            pattern: '- (Required) Pattern of the ACL.'
            permission: |-
                - (Required) Permission of the ACL
                Available permission:
            service_name: |-
                - (Required, Forces new resource) The id of the public cloud project. If omitted,
                the OVH_CLOUD_PROJECT_SERVICE environment variable is used.
            status: '- Current status of the user.'
            update: '- (Default 20m)'
        importStatements: []
    ovh_cloud_project_database_postgresql_user:
        subCategory: ""
        name: ovh_cloud_project_database_postgresql_user
        title: ""
        examples:
            - name: user
              manifest: |-
                {
                  "cluster_id": "${data.ovh_cloud_project_database.postgresql.id}",
                  "name": "johndoe",
                  "roles": [
                    "replication"
                  ],
                  "service_name": "${data.ovh_cloud_project_database.postgresql.service_name}"
                }
              references:
                cluster_id: data.ovh_cloud_project_database.postgresql.id
                service_name: data.ovh_cloud_project_database.postgresql.service_name
            - name: user
              manifest: |-
                {
                  "cluster_id": "${data.ovh_cloud_project_database.postgresql.id}",
                  "name": "johndoe",
                  "password_reset": "reset1",
                  "roles": [
                    "replication"
                  ],
                  "service_name": "${data.ovh_cloud_project_database.postgresql.service_name}"
                }
              references:
                cluster_id: data.ovh_cloud_project_database.postgresql.id
                service_name: data.ovh_cloud_project_database.postgresql.service_name
            - name: user
              manifest: |-
                {
                  "timeouts": [
                    {
                      "create": "1h",
                      "delete": "50s",
                      "update": "45m"
                    }
                  ]
                }
        argumentDocs:
            cluster_id: '- (Required, Forces new resource) Cluster ID.'
            create: '- (Default 20m)'
            created_at: '- Date of the creation of the user.'
            delete: '- (Default 20m)'
            id: '- ID of the user.'
            name: '- (Required, Forces new resource) Name of the user. A user named "avnadmin" is map with already created admin user and reset his password instead of create a new user.'
            password: '- (Sensitive) Password of the user.'
            password_reset: '- (Optional) Arbitrary string to change to trigger a password update. Use the terraform refresh command after executing terraform apply to update the output with the new password.'
            roles: |-
                - (Optional: if omit, default role) Roles the user belongs to.
                Available roles:
            service_name: |-
                - (Required, Forces new resource) The id of the public cloud project. If omitted,
                the OVH_CLOUD_PROJECT_SERVICE environment variable is used.
            status: '- Current status of the user.'
            update: '- (Default 20m)'
        importStatements: []
    ovh_cloud_project_database_redis_user:
        subCategory: ""
        name: ovh_cloud_project_database_redis_user
        title: ""
        examples:
            - name: user
              manifest: |-
                {
                  "categories": [
                    "+@set",
                    "+@sortedset"
                  ],
                  "channels": [
                    "*"
                  ],
                  "cluster_id": "${data.ovh_cloud_project_database.redis.id}",
                  "commands": [
                    "+get",
                    "-set"
                  ],
                  "keys": [
                    "data",
                    "properties"
                  ],
                  "name": "johndoe",
                  "service_name": "${data.ovh_cloud_project_database.redis.service_name}"
                }
              references:
                cluster_id: data.ovh_cloud_project_database.redis.id
                service_name: data.ovh_cloud_project_database.redis.service_name
            - name: user
              manifest: |-
                {
                  "categories": [
                    "+@set",
                    "+@sortedset"
                  ],
                  "channels": [
                    "*"
                  ],
                  "cluster_id": "${data.ovh_cloud_project_database.redis.id}",
                  "commands": [
                    "+get",
                    "-set"
                  ],
                  "keys": [
                    "data",
                    "properties"
                  ],
                  "name": "johndoe",
                  "password_reset": "reset1",
                  "service_name": "${data.ovh_cloud_project_database.redis.service_name}"
                }
              references:
                cluster_id: data.ovh_cloud_project_database.redis.id
                service_name: data.ovh_cloud_project_database.redis.service_name
            - name: user
              manifest: |-
                {
                  "timeouts": [
                    {
                      "create": "1h",
                      "delete": "50s",
                      "update": "45m"
                    }
                  ]
                }
        argumentDocs:
            categories: '- (Optional) Categories of the user.'
            channels: '- (Optional: if omit, all channels) Channels of the user.'
            cluster_id: '- (Required, Forces new resource) Cluster ID.'
            commands: '- (Optional) Commands of the user.'
            create: '- (Default 20m)'
            created_at: '- Date of the creation of the user.'
            delete: '- (Default 20m)'
            id: '- ID of the user.'
            keys: '- (Optional) Keys of the user.'
            name: '- (Required, Forces new resource) Name of the user. A user named "avnadmin" is map with already created admin user and reset his password instead of create a new user.'
            password: '- (Sensitive) Password of the user.'
            password_reset: '- (Optional) Arbitrary string to change to trigger a password update. Use the terraform refresh command after executing terraform apply to update the output with the new password.'
            service_name: |-
                - (Required, Forces new resource) The id of the public cloud project. If omitted,
                the OVH_CLOUD_PROJECT_SERVICE environment variable is used.
            status: '- Current status of the user.'
            update: '- (Default 20m)'
        importStatements: []
    ovh_cloud_project_database_user:
        subCategory: ""
        name: ovh_cloud_project_database_user
        title: ""
        examples:
            - name: user
              manifest: |-
                {
                  "cluster_id": "${data.ovh_cloud_project_database.db.id}",
                  "engine": "${data.ovh_cloud_project_database.db.engine}",
                  "name": "johndoe",
                  "service_name": "${data.ovh_cloud_project_database.db.service_name}"
                }
              references:
                cluster_id: data.ovh_cloud_project_database.db.id
                engine: data.ovh_cloud_project_database.db.engine
                service_name: data.ovh_cloud_project_database.db.service_name
            - name: user
              manifest: |-
                {
                  "cluster_id": "${data.ovh_cloud_project_database.db.id}",
                  "engine": "${data.ovh_cloud_project_database.db.engine}",
                  "name": "johndoe",
                  "password_reset": "reset1",
                  "service_name": "${data.ovh_cloud_project_database.db.service_name}"
                }
              references:
                cluster_id: data.ovh_cloud_project_database.db.id
                engine: data.ovh_cloud_project_database.db.engine
                service_name: data.ovh_cloud_project_database.db.service_name
            - name: user
              manifest: |-
                {
                  "timeouts": [
                    {
                      "create": "1h",
                      "delete": "50s",
                      "update": "45m"
                    }
                  ]
                }
        argumentDocs:
            cluster_id: '- (Required, Forces new resource) Cluster ID.'
            create: '- (Default 20m)'
            created_at: '- Date of the creation of the user.'
            delete: '- (Default 20m)'
            engine: |-
                - (Required, Forces new resource) The engine of the database cluster you want to add. You can find the complete list of available engine in the public documentation.
                Available engines:
            id: '- ID of the user.'
            name: '- (Required, Forces new resource) Name of the user. A user named "avnadmin" is map with already created admin user and reset his password instead of create a new user. The "Grafana" engine only allows the "avnadmin" mapping.'
            password: '- (Sensitive) Password of the user.'
            password_reset: '- (Optional) Arbitrary string to change to trigger a password update. Use the terraform refresh command after executing terraform apply to update the output with the new password.'
            service_name: |-
                - (Required, Forces new resource) The id of the public cloud project. If omitted,
                the OVH_CLOUD_PROJECT_SERVICE environment variable is used.
            status: '- Current status of the user.'
            update: '- (Default 20m)'
        importStatements: []
    ovh_cloud_project_failover_ip_attach:
        subCategory: ""
        name: ovh_cloud_project_failover_ip_attach
        title: ""
        examples:
            - name: myfailoverip
              manifest: |-
                {
                  "ip": "XXXXXX",
                  "routed_to": "XXXXXX",
                  "service_name": "XXXXXX"
                }
        argumentDocs:
            block: '- The IP block'
            continentCode: '- The Ip continent'
            geoloc: '- The Ip location'
            id: '- The Ip id'
            ip: '- The failover ip address to attach'
            progress: '- Current operation progress in percent'
            routed_to: '- The GUID of an instance to which the failover IP address is be attached'
            routedTo: '- Instance where ip is routed to'
            service_name: |-
                - The id of the public cloud project. If omitted,
                the OVH_CLOUD_PROJECT_SERVICE environment variable is used.
            status: '- Ip status, can be ok or operationPending'
            subType: '- IP sub type, can be cloud or ovh'
        importStatements: []
    ovh_cloud_project_kube:
        subCategory: ""
        name: ovh_cloud_project_kube
        title: ""
        examples:
            - name: mycluster
              manifest: |-
                {
                  "name": "my_kube_cluster",
                  "region": "GRA7",
                  "service_name": "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
                }
            - name: mycluster
              manifest: |-
                {
                  "name": "my_kube_cluster",
                  "region": "GRA7",
                  "service_name": "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
                }
            - name: mycluster
              manifest: |-
                {
                  "name": "my_kube_cluster",
                  "region": "GRA7",
                  "service_name": "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
                }
            - name: mycluster
              manifest: |-
                {
                  "name": "my_kube_cluster",
                  "region": "GRA7",
                  "service_name": "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
                }
            - name: mycluster
              manifest: |-
                {
                  "customization_apiserver": [
                    {
                      "admissionplugins": [
                        {
                          "disabled": [
                            "AlwaysPullImages"
                          ],
                          "enabled": [
                            "NodeRestriction"
                          ]
                        }
                      ]
                    }
                  ],
                  "name": "my_kube_cluster",
                  "region": "GRA5",
                  "service_name": "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
                }
            - name: mycluster
              manifest: |-
                {
                  "customization_kube_proxy": [
                    {
                      "iptables": [
                        {
                          "min_sync_period": "PT0S",
                          "sync_period": "PT0S"
                        }
                      ],
                      "ipvs": [
                        {
                          "min_sync_period": "PT0S",
                          "scheduler": "rr",
                          "sync_period": "PT0S",
                          "tcp_fin_timeout": "PT0S",
                          "tcp_timeout": "PT0S",
                          "udp_timeout": "PT0S"
                        }
                      ]
                    }
                  ],
                  "kube_proxy_mode": "ipvs",
                  "name": "my_kube_cluster",
                  "region": "GRA5",
                  "service_name": "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
                }
            - name: mycluster
              manifest: |-
                {
                  "depends_on": [
                    "${ovh_cloud_project_network_private.network}"
                  ],
                  "name": "test-kube-attach",
                  "private_network_configuration": [
                    {
                      "default_vrack_gateway": "",
                      "private_network_routing_as_default": false
                    }
                  ],
                  "private_network_id": "${tolist(ovh_cloud_project_network_private.network.regions_attributes[*].openstackid)[0]}",
                  "region": "GRA5",
                  "service_name": "${var.service_name}"
                }
              references:
                service_name: var.service_name
              dependencies:
                ovh_cloud_project_network_private.network: |-
                    {
                      "depends_on": [
                        "${ovh_vrack_cloudproject.attach}"
                      ],
                      "name": "terraform_testacc_private_net",
                      "regions": [
                        "GRA5"
                      ],
                      "service_name": "${ovh_vrack_cloudproject.attach.service_name}",
                      "vlan_id": 0
                    }
                ovh_cloud_project_network_private_subnet.networksubnet: |-
                    {
                      "depends_on": [
                        "${ovh_cloud_project_network_private.network}"
                      ],
                      "dhcp": true,
                      "end": "192.168.168.200",
                      "network": "192.168.168.0/24",
                      "network_id": "${ovh_cloud_project_network_private.network.id}",
                      "no_gateway": false,
                      "region": "GRA5",
                      "service_name": "${ovh_cloud_project_network_private.network.service_name}",
                      "start": "192.168.168.100"
                    }
                ovh_vrack_cloudproject.attach: |-
                    {
                      "project_id": "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx",
                      "service_name": "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
                    }
            - name: my_kube_cluster
              manifest: |-
                {
                  "timeouts": [
                    {
                      "create": "1h",
                      "delete": "50s",
                      "update": "45m"
                    }
                  ]
                }
        argumentDocs:
            admissionplugins: '- (Optional) Kubernetes API server admission plugins customization'
            apiserver: '- Kubernetes API server customization'
            client_certificate: '- The kubernetes API server client certificate.'
            client_key: '- The kubernetes API server client key.'
            cluster_ca_certificate: '- The kubernetes API server CA certificate.'
            control_plane_is_up_to_date: '- True if control-plane is up-to-date.'
            create: '- (Default 10m)'
            customization: '- Deprecated (Optional) Use customization_apiserver and customization_kube_proxy instead. Kubernetes cluster customization'
            customization_apiserver: '- Kubernetes API server customization'
            customization_kube_proxy: '- Kubernetes kube-proxy customization'
            default_vrack_gateway: '- If defined, all egress traffic will be routed towards this IP address, which should belong to the private network. Empty string means disabled.'
            delete: '- (Default 10m)'
            disabled: '- (Optional) Array of admission plugins disabled, default is [] and only AlwaysPulImages can be disabled at this time.'
            enabled: '- (Optional) Array of admission plugins enabled, default is ["NodeRestriction","AlwaysPulImages"] and only these admission plugins can be enabled at this time.'
            host: '- The kubernetes API server URL.'
            id: '- Managed Kubernetes Service ID'
            iptables: '- (Optional) Kubernetes cluster kube-proxy customization of iptables specific config (durations format is RFC3339 duration, e.g. PT60S)'
            ipvs: '- (Optional) Kubernetes cluster kube-proxy customization of IPVS specific config (durations format is RFC3339 duration, e.g. PT60S)'
            is_up_to_date: '- True if all nodes and control-plane are up-to-date.'
            kube_proxy: '- Kubernetes kube-proxy customization'
            kube_proxy_mode: '- (Optional) Selected mode for kube-proxy. Changing this value recreates the resource, including ETCD user data. Defaults to iptables.'
            kubeconfig: '- The kubeconfig file. Use this file to connect to your kubernetes cluster.'
            kubeconfig_attributes: '- The kubeconfig file attributes.'
            min_sync_period: '- (Optional) Period that iptables rules are refreshed, in RFC3339 duration format (e.g. PT60S). Must be greater than 0.'
            name: '- (Optional) The name of the kubernetes cluster.'
            next_upgrade_versions: '- Kubernetes versions available for upgrade.'
            nodes_url: '- Cluster nodes URL.'
            private_network_configuration: '- (Optional) The private network configuration'
            private_network_id: '- (Optional) OpenStack private network (or vRack) ID to use. Changing this value recreates the resource, including ETCD user data. Defaults - not use private network.'
            private_network_routing_as_default: '- Defines whether routing should default to using the nodes'' private interface, instead of their public interface. Default is false.'
            region: '- a valid OVHcloud public cloud region ID in which the kubernetes cluster will be available. Ex.: "GRA1". Defaults to all public cloud regions. Changing this value recreates the resource.'
            scheduler: '- (Optional) IPVS scheduler.'
            service_name: '- The id of the public cloud project. If omitted, the OVH_CLOUD_PROJECT_SERVICE environment variable is used. Changing this value recreates the resource.'
            status: '- Cluster status. Should be normally set to ''READY''.'
            sync_period: '- (Optional) Minimum period that iptables rules are refreshed, in RFC3339 duration format (e.g. PT60S).'
            tcp_fin_timeout: '- (Optional) Timeout value used for IPVS TCP sessions after receiving a FIN in RFC3339 duration (e.g. PT60S). The default value is PT0S, which preserves the current timeout value on the system.'
            tcp_timeout: '- (Optional) Timeout value used for idle IPVS TCP sessions in RFC3339 duration (e.g. PT60S). The default value is PT0S, which preserves the current timeout value on the system.'
            udp_timeout: '- (Optional) timeout value used for IPVS UDP packets in RFC3339 duration (e.g. PT60S). The default value is PT0S, which preserves the current timeout value on the system.'
            update: '- (Default 10m)'
            update_policy: '- Cluster update policy. Choose between [ALWAYS_UPDATE, MINIMAL_DOWNTIME, NEVER_UPDATE].'
            url: '- Management URL of your cluster.'
            version: '- (Optional) kubernetes version to use. Changing this value updates the resource. Defaults to the latest available.'
        importStatements: []
    ovh_cloud_project_kube_iprestrictions:
        subCategory: ""
        name: ovh_cloud_project_kube_iprestrictions
        title: ""
        examples:
            - name: vrack_only
              manifest: |-
                {
                  "ips": [
                    "10.42.0.0/16"
                  ],
                  "kube_id": "xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxx",
                  "service_name": "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
                }
            - name: vrack_only
              manifest: |-
                {
                  "timeouts": [
                    {
                      "create": "1h",
                      "delete": "50s",
                      "update": "45m"
                    }
                  ]
                }
        argumentDocs:
            create: '- (Default 10m)'
            delete: '- (Default 5m)'
            ips: '- List of CIDR authorized to interact with the managed Kubernetes cluster.'
            kube_id: '- The id of the managed Kubernetes cluster. Changing this value recreates the resource.'
            service_name: '- The id of the public cloud project. If omitted, the OVH_CLOUD_PROJECT_SERVICE environment variable is used. Changing this value recreates the resource.'
            update: '- (Default 5m)'
        importStatements: []
    ovh_cloud_project_kube_nodepool:
        subCategory: ""
        name: ovh_cloud_project_kube_nodepool
        title: ""
        examples:
            - name: node_pool
              manifest: |-
                {
                  "desired_nodes": 3,
                  "flavor_name": "b2-7",
                  "kube_id": "xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx",
                  "max_nodes": 3,
                  "min_nodes": 3,
                  "name": "my-pool-1",
                  "service_name": "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
                }
            - name: pool
              manifest: |-
                {
                  "desired_nodes": 3,
                  "flavor_name": "b2-7",
                  "kube_id": "xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx",
                  "max_nodes": 3,
                  "min_nodes": 3,
                  "name": "my-pool",
                  "service_name": "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx",
                  "template": [
                    {
                      "metadata": [
                        {
                          "annotations": {
                            "k1": "v1",
                            "k2": "v2"
                          },
                          "finalizers": [
                            "F1",
                            "F2"
                          ],
                          "labels": {
                            "k3": "v3",
                            "k4": "v4"
                          }
                        }
                      ],
                      "spec": [
                        {
                          "taints": [
                            {
                              "effect": "PreferNoSchedule",
                              "key": "k",
                              "value": "v"
                            }
                          ],
                          "unschedulable": false
                        }
                      ]
                    }
                  ]
                }
            - name: pool
              manifest: |-
                {
                  "timeouts": [
                    {
                      "create": "1h",
                      "delete": "50s",
                      "update": "45m"
                    }
                  ]
                }
        argumentDocs:
            annotations: '- (Optional) Annotations to apply to each node'
            anti_affinity: '- (Optional) should the pool use the anti-affinity feature. Default to false. Changing this value recreates the resource.'
            autoscale: '- (Optional) Enable auto-scaling for the pool. Default to false.'
            available_nodes: '- Number of nodes which are actually ready in the pool'
            create: '- (Default 20m)'
            created_at: '- Creation date'
            current_nodes: '- Number of nodes present in the pool'
            delete: '- (Default 10m)'
            desired_nodes: '- number of nodes to start.'
            finalizers: '- (Optional) Finalizers to apply to each node'
            flavor: '- Flavor name'
            flavor_name: |-
                - a valid OVHcloud public cloud flavor ID in which the nodes will be started. Ex: "b2-7". You can find the list of flavor IDs: https://www.ovhcloud.com/fr/public-cloud/prices/.
                Changing this value recreates the resource.
            kube_id: '- The id of the managed kubernetes cluster. Changing this value recreates the resource.'
            labels: '- (Optional) Labels to apply to each node'
            max_nodes: '- maximum number of nodes allowed in the pool. Setting desired_nodes over this value will raise an error.'
            metadata: '- (Optional) Metadata of each node in the pool'
            min_nodes: '- minimum number of nodes allowed in the pool. Setting desired_nodes under this value will raise an error.'
            monthly_billed: '- (Optional) should the nodes be billed on a monthly basis. Default to false. Changing this value recreates the resource.'
            name: '- (Optional) The name of the nodepool. Warning: _ char is not allowed! Changing this value recreates the resource.'
            project_id: '- Project id'
            service_name: '- The id of the public cloud project. If omitted, the OVH_CLOUD_PROJECT_SERVICE environment variable is used. Changing this value recreates the resource.'
            size_status: '- Status describing the state between number of nodes wanted and available ones'
            spec: '- (Optional) Spec of each node in the pool'
            status: '- Current status'
            taints: '- (Optional) Taints to apply to each node'
            'template ': '- (Optional) Managed Kubernetes nodepool template, which is a complex object constituted by two main nested objects:'
            unschedulable: '- (Optional) If true, set nodes as un-schedulable'
            up_to_date_nodes: '- Number of nodes with the latest version installed in the pool'
            update: '- (Default 10m)'
            updated_at: '- Last update date'
        importStatements: []
    ovh_cloud_project_kube_oidc:
        subCategory: ""
        name: ovh_cloud_project_kube_oidc
        title: ""
        examples:
            - name: my-oidc
              manifest: |-
                {
                  "client_id": "xxx",
                  "issuer_url": "https://ovh.com",
                  "kube_id": "${ovh_cloud_project_kube.mykube.id}",
                  "oidc_ca_content": "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",
                  "oidc_groups_claim": [
                    "groups"
                  ],
                  "oidc_groups_prefix": "ovh:",
                  "oidc_required_claim": [
                    "claim1=val1"
                  ],
                  "oidc_signing_algs": [
                    "RS512"
                  ],
                  "oidc_username_claim": "an-email",
                  "oidc_username_prefix": "ovh:",
                  "service_name": "${var.projectid}"
                }
              references:
                kube_id: ovh_cloud_project_kube.mykube.id
                service_name: var.projectid
            - name: oidc
              manifest: |-
                {
                  "timeouts": [
                    {
                      "create": "1h",
                      "delete": "50s",
                      "update": "45m"
                    }
                  ]
                }
        argumentDocs:
            client_id: '- The OIDC client ID.'
            create: '- (Default 10m)'
            delete: '- (Default 10m)'
            issuer_url: '- The OIDC issuer url.'
            kube_id: '- The ID of the managed kubernetes cluster. Changing this value recreates the resource.'
            oidcCaContent: '- Content of the certificate for the CA, in Base64 format, that signed your identity provider''s web certificate. Defaults to the host''s root CAs.'
            oidcGroupsClaim: '- Array of JWT claim to use as the user''s group. If the claim is present it must be an array of strings.'
            oidcGroupsPrefix: '- Prefix prepended to group claims to prevent clashes with existing names (such as system:groups). For example, the value oidc: will create group names like oidc:engineering and oidc:infra.'
            oidcRequiredClaim: '- Array of key=value pairs that describe required claims in the ID Token. If set, the claims are verified to be present in the ID Token with a matching value."'
            oidcSigningAlgs: '- Array of signing algorithms accepted. Default is RS256.'
            oidcUsernameClaim: '- JWT claim to use as the username. By default, sub, which is expected to be a unique identifier of the end user. Admins can choose other claims, such as email or name, depending on their provider. However, claims other than email will be prefixed with the issuer URL to prevent naming clashes with other plugins.'
            oidcUsernamePrefix: '- Prefix prepended to username claims to prevent clashes with existing names (such as system:users). For example, the value oidc: will create usernames like oidc:jane.doe. If this field isn''t set and oidcUsernameClaim is a value other than email the prefix defaults to issuer_url where issuer_url is the value of oidcIssuerUrl. The value - can be used to disable all prefixing.'
            service_name: '- The ID of the public cloud project. If omitted, the OVH_CLOUD_PROJECT_SERVICE environment variable is used. Changing this value recreates the resource.'
            update: '- (Default 10m)'
        importStatements: []
    ovh_cloud_project_network_private:
        subCategory: ""
        name: ovh_cloud_project_network_private
        title: ""
        examples:
            - name: net
              manifest: |-
                {
                  "name": "admin_network",
                  "regions": [
                    "GRA1",
                    "BHS1"
                  ],
                  "service_name": "XXXXXX"
                }
        argumentDocs:
            id: '- The id of the network'
            name: '- (Required) The name of the network.'
            regions: |-
                - an array of valid OVHcloud public cloud region ID in which the network
                will be available. Ex.: "GRA1". Defaults to all public cloud regions.
            regions_attributes: '- A map representing information about the region.'
            regions_attributes/openstackid: '- The private network id in the region.'
            regions_attributes/region: '- The id of the region.'
            regions_attributes/status: '- The status of the network in the region.'
            regions_status: '- (Deprecated) A map representing the status of the network per region.'
            regions_status/region: '- (Deprecated) The id of the region.'
            regions_status/status: '- (Deprecated) The status of the network in the region.'
            service_name: |-
                - (Required) The id of the public cloud project. If omitted,
                the OVH_CLOUD_PROJECT_SERVICE environment variable is used.
            status: '- the status of the network. should be normally set to ''ACTIVE''.'
            type: '- the type of the network. Either ''private'' or ''public''.'
            vlan_id: |-
                - a vlan id to associate with the network.
                Changing this value recreates the resource. Defaults to 0.
        importStatements: []
    ovh_cloud_project_network_private_subnet:
        subCategory: ""
        name: ovh_cloud_project_network_private_subnet
        title: ""
        examples:
            - name: subnet
              manifest: |-
                {
                  "dhcp": true,
                  "end": "192.168.168.200",
                  "network": "192.168.168.0/24",
                  "network_id": "0234543",
                  "no_gateway": false,
                  "region": "GRA1",
                  "service_name": "xxxxx",
                  "start": "192.168.168.100"
                }
        argumentDocs:
            cidr: '- Ip Block representing the subnet cidr.'
            dhcp: |-
                - (Optional) Enable DHCP.
                Changing this forces a new resource to be created. Defaults to false.
                _
            dhcp_id: '- See Argument Reference above.'
            end: |-
                - (Required) Last ip for this region.
                Changing this value recreates the subnet.
            gateway_ip: '- The IP of the gateway'
            ip_pools: '- List of ip pools allocated in the subnet.'
            ip_pools/dhcp: '- DHCP enabled.'
            ip_pools/end: '- Last ip for this region.'
            ip_pools/network: '- Global network with cidr.'
            ip_pools/region: '- Region where this subnet is created.'
            ip_pools/start: '- First ip for this region.'
            network: |-
                - (Required) Global network in CIDR format.
                Changing this value recreates the subnet
            network_id: |-
                - (Required) The id of the network.
                Changing this forces a new resource to be created.
            no_gateway: |-
                - Set to true if you don't want to set a default gateway IP.
                Changing this value recreates the resource. Defaults to false.
            region: |-
                - The region in which the network subnet will be created.
                Ex.: "GRA1". Changing this value recreates the resource.
            service_name: |-
                - (Required) The id of the public cloud project. If omitted,
                the OVH_CLOUD_PROJECT_SERVICE environment variable is used.
            start: |-
                - (Required) First ip for this region.
                Changing this value recreates the subnet.
        importStatements: []
    ovh_cloud_project_region_storage_presign:
        subCategory: ""
        name: ovh_cloud_project_region_storage_presign
        title: ""
        examples:
            - name: presigned_url
              manifest: |-
                {
                  "expire": 3600,
                  "method": "GET",
                  "name": "s3-bucket-name",
                  "object": "an-object-in-the-bucket",
                  "region_name": "GRA",
                  "service_name": "xxxxxxxxxxxxxxxxx"
                }
        argumentDocs:
            expire: '- (Required) Define, in seconds, for how long your URL will be valid.'
            method: '- (Required) The method you want to use to interact with your object. Can be either ''GET'' or ''PUT''.'
            name: '- (Required) The name of your S3 storage container/bucket.'
            object: '- (Required) The name of the object in your S3 bucket.'
            region_name: |-
                - (Required) The region in which your storage is located.
                Ex.: "GRA".
            service_name: |-
                - (Required) The id of the public cloud project. If omitted,
                the OVH_CLOUD_PROJECT_SERVICE environment variable is used.
            url: '- Computed URL result.'
        importStatements: []
    ovh_cloud_project_user:
        subCategory: ""
        name: ovh_cloud_project_user
        title: ""
        examples:
            - name: user1
              manifest: |-
                {
                  "service_name": "XXX"
                }
        argumentDocs:
            creation_date: '- the date the user was created.'
            description: '- A description associated with the user.'
            id: '- id of the role'
            name: '- name of the role'
            openstack_rc: |-
                - a convenient map representing an openstack_rc file.
                Note: no password nor sensitive token is set in this map.
            password: |-
                - (Sensitive) the password generated for the user. The password can
                be used with the Openstack API. This attribute is sensitive and will only be
                retrieve once during creation.
            permissions: '- list of permissions associated with the role'
            role_name: '-  The name of a role. See role_names.'
            role_names: '- A list of role names. Values can be:'
            roles: '- A list of roles associated with the user.'
            service_name: |-
                - (Required) The id of the public cloud project. If omitted,
                the OVH_CLOUD_PROJECT_SERVICE environment variable is used.
            status: '- the status of the user. should be normally set to ''ok''.'
            username: |-
                - the username generated for the user. This username can be used with
                the Openstack API.
        importStatements: []
    ovh_cloud_project_user_s3_policy:
        subCategory: ""
        name: ovh_cloud_project_user_s3_policy
        title: ""
        examples:
            - name: policy
              manifest: |-
                {
                  "policy": "${jsonencode({\n    \"Statement\":[{\n      \"Sid\": \"RWContainer\",\n      \"Effect\": \"Allow\",\n      \"Action\":[\"s3:GetObject\", \"s3:PutObject\", \"s3:DeleteObject\", \"s3:ListBucket\", \"s3:ListMultipartUploadParts\", \"s3:ListBucketMultipartUploads\", \"s3:AbortMultipartUpload\", \"s3:GetBucketLocation\"],\n      \"Resource\":[\"arn:aws:s3:::hp-bucket\", \"arn:aws:s3:::hp-bucket/*\"]\n    }]\n  })}",
                  "service_name": "${ovh_cloud_project_user.user.service_name}",
                  "user_id": "${ovh_cloud_project_user.user.id}"
                }
              references:
                service_name: ovh_cloud_project_user.user.service_name
                user_id: ovh_cloud_project_user.user.id
              dependencies:
                ovh_cloud_project_user.user: |-
                    {
                      "description": "my user",
                      "role_names": [
                        "objectstore_operator"
                      ],
                      "service_name": "XXX"
                    }
                ovh_cloud_project_user_s3_credential.my_s3_credentials: |-
                    {
                      "service_name": "${ovh_cloud_project_user.user.service_name}",
                      "user_id": "${ovh_cloud_project_user.user.id}"
                    }
        argumentDocs:
            policy: '- (Required) The policy document. This is a JSON formatted string. See examples of policies on public documentation.'
            service_name: |-
                - (Required) The ID of the public cloud project. If omitted,
                the OVH_CLOUD_PROJECT_SERVICE environment variable is used.
            user_id: '- (Required) The ID of a public cloud project''s user.'
        importStatements: []
    ovh_cloud_project_workflow_backup:
        subCategory: ""
        name: ovh_cloud_project_workflow_backup
        title: ""
        examples:
            - name: my_backup
              manifest: |-
                {
                  "cron": "50 4 * * *",
                  "instance_id": "xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxx",
                  "max_execution_count": "0",
                  "name": "Backup workflow for instance",
                  "region_name": "GRA11",
                  "rotation": "7",
                  "service_name": "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
                }
        argumentDocs:
            backup_name: '- (Optional) The name of the backup files that are created. If empty, the name attribute is used.'
            cron: '- (Mandatory) The cron periodicity at which the backup workflow is scheduled'
            instanceId: the id of the instance to back up
            max_execution_count: '- (Optional) The number of times the worflow is run. Default value is 0 which means that the workflow will be scheduled continously until its deletion'
            name: '- (Mandatory) The worflow name that is used in the UI'
            region_name: '- (Mandatory) The name of the openstack region.'
            rotation: '- (Mandatory) The number of backup that are retained.'
            service_name: '- (Optional) The id of the public cloud project. If omitted, the OVH_CLOUD_PROJECT_SERVICE environment variable is used.'
        importStatements: []
    ovh_dbaas_logs_cluster:
        subCategory: ""
        name: ovh_dbaas_logs_cluster
        title: ""
        examples:
            - name: ldp
              manifest: |-
                {
                  "archive_allowed_networks": [
                    "10.0.0.0/16"
                  ],
                  "direct_input_allowed_networks": [
                    "10.0.0.0/16"
                  ],
                  "query_allowed_networks": [
                    "10.0.0.0/16"
                  ],
                  "service_name": "ldp-xx-xxxxx"
                }
        argumentDocs:
            archive_allowed_networks: '- List of IP blocks'
            cluster_type: is type of cluster (DEDICATED, PRO or TRIAL)
            dedicated_input_pem: is PEM for dedicated inputs
            direct_input_allowed_networks: '- List of IP blocks'
            direct_input_pem: is PEM for direct inputs
            hostname: is cluster hostname hosting the tenant
            is_default: is true if all content generated by given service will be placed on this cluster
            is_unlocked: is true if given service can perform advanced operations on cluster
            query_allowed_networks: '- List of IP blocks'
            region: is datacenter localization
        importStatements: []
    ovh_dbaas_logs_input:
        subCategory: ""
        name: ovh_dbaas_logs_input
        title: ""
        examples:
            - name: input
              manifest: |-
                {
                  "allowed_networks": [
                    "10.0.0.0/16"
                  ],
                  "configuration": [
                    {
                      "logstash": [
                        {
                          "input_section": "  beats {\n    port =\u003e 6514\n    ssl =\u003e true\n    ssl_certificate =\u003e \"/etc/ssl/private/server.crt\"\n    ssl_key =\u003e \"/etc/ssl/private/server.key\"\n  }\n"
                        }
                      ]
                    }
                  ],
                  "description": "${ovh_dbaas_logs_output_graylog_stream.stream.description}",
                  "engine_id": "${data.ovh_dbaas_logs_input_engine.logstash.id}",
                  "exposed_port": "6154",
                  "nb_instance": 2,
                  "service_name": "${ovh_dbaas_logs_output_graylog_stream.stream.service_name}",
                  "stream_id": "${ovh_dbaas_logs_output_graylog_stream.stream.id}",
                  "title": "${ovh_dbaas_logs_output_graylog_stream.stream.title}"
                }
              references:
                description: ovh_dbaas_logs_output_graylog_stream.stream.description
                engine_id: data.ovh_dbaas_logs_input_engine.logstash.id
                service_name: ovh_dbaas_logs_output_graylog_stream.stream.service_name
                stream_id: ovh_dbaas_logs_output_graylog_stream.stream.id
                title: ovh_dbaas_logs_output_graylog_stream.stream.title
              dependencies:
                ovh_dbaas_logs_output_graylog_stream.stream: |-
                    {
                      "description": "my graylog stream",
                      "service_name": "....",
                      "title": "my stream"
                    }
        argumentDocs:
            allowed_networks: '- List of IP blocks'
            configuration: '- (Required) Input configuration'
            created_at: '- Input creation'
            description: '- (Required) Input description'
            engine_id: '- (Required) Input engine ID'
            exposed_port: '- Port'
            filter_section: '- (Optional) The filter section of logstash.conf'
            flowgger: '- (Optional) Flowgger configuration'
            hostname: '- Hostname'
            input_id: '- Input ID'
            input_section: '- (Required) The filter section of logstash.conf'
            is_restart_required: '- Indicate if input need to be restarted'
            log_format: '- Type of format to decode. One of "RFC5424", "LTSV", "GELF", "CAPNP"'
            log_framing: '- Indicates how messages are delimited. One of "LINE", "NUL", "SYSLEN", "CAPNP"'
            logstash: '- (Optional) Logstash configuration'
            nb_instance: '- Number of instance running'
            pattern_section: '- (Optional) The list of customs Grok patterns'
            public_address: '- Input IP address'
            service_name: '- (Required) service name'
            ssl_certificate: '- Input SSL certificate'
            status: '- init: configuration required, pending: ready to start, running: available'
            stream_id: '- (Required) Associated Graylog stream'
            title: '- (Required) Input title'
            updated_at: '- Input last update'
        importStatements: []
    ovh_dedicated_ceph_acl:
        subCategory: ""
        name: ovh_dedicated_ceph_acl
        title: ""
        examples:
            - name: my-acl
              manifest: |-
                {
                  "netmask": "255.255.255.255",
                  "network": "1.2.3.4",
                  "service_name": "${data.ovh_dedicated_ceph.my-ceph.id}"
                }
              references:
                service_name: data.ovh_dedicated_ceph.my-ceph.id
        argumentDocs:
            family: '- IP family. IPv4 or IPv6'
            netmask: '- (Required) The network mask to apply'
            network: '- (Required) The network IP to authorize'
            service_name: '- (Required) The internal name of your dedicated CEPH'
        importStatements: []
    ovh_dedicated_nasha_partition:
        subCategory: ""
        name: ovh_dedicated_nasha_partition
        title: ""
        examples:
            - name: my-partition
              manifest: |-
                {
                  "name": "my-partition",
                  "protocol": "NFS",
                  "service_name": "zpool-12345",
                  "size": 20
                }
        argumentDocs:
            capacity: '- Percentage of partition space used in %'
            description: '- A brief description of the partition'
            name: '- (Required) name of the partition'
            protocol: '- (Required) one of "NFS", "CIFS" or "NFS_CIFS"'
            service_name: '- (Required) The internal name of your HA-NAS (it has to be ordered via OVHcloud interface)'
            size: '- (Required) size of the partition in GB'
            used_by_snapshots: '- Percentage of partition space used by snapshots in %'
        importStatements: []
    ovh_dedicated_nasha_partition_access:
        subCategory: ""
        name: ovh_dedicated_nasha_partition_access
        title: ""
        examples:
            - name: my-partition
              manifest: |-
                {
                  "ip": "123.123.123.123/32",
                  "partition_name": "my-partition",
                  "service_name": "zpool-12345",
                  "type": "readwrite"
                }
        argumentDocs:
            ip: '- (Required) ip block in x.x.x.x/x format'
            partition_name: '- (Required) name of the partition'
            service_name: '- (Required) The internal name of your HA-NAS (it has to be ordered via OVHcloud interface)'
            type: '- (Required) one of "readwrite", "readonly"'
        importStatements: []
    ovh_dedicated_nasha_partition_snapshot:
        subCategory: ""
        name: ovh_dedicated_nasha_partition_snapshot
        title: ""
        examples:
            - name: my-partition
              manifest: |-
                {
                  "partition_name": "my-partition",
                  "service_name": "zpool-12345",
                  "type": "day-3"
                }
        argumentDocs:
            partition_name: '- (Required) name of the partition'
            service_name: '- (Required) The internal name of your HA-NAS (it has to be ordered via OVHcloud interface)'
            type: '- (Required) Snapshot interval, allowed : day-1, day-2, day-3, day-7, hour-1, hour-6'
        importStatements: []
    ovh_dedicated_server_install_task:
        subCategory: ""
        name: ovh_dedicated_server_install_task
        title: ""
        examples:
            - name: server_install
              manifest: |-
                {
                  "bootid_on_destroy": "${data.ovh_dedicated_server_boots.rescue.result[0]}",
                  "details": [
                    {
                      "custom_hostname": "mytest"
                    }
                  ],
                  "service_name": "nsxxxxxxx.ip-xx-xx-xx.eu",
                  "template_name": "${ovh_me_installation_template.debian.template_name}"
                }
              references:
                bootid_on_destroy: data.ovh_dedicated_server_boots.rescue.result[0]
                template_name: ovh_me_installation_template.debian.template_name
              dependencies:
                ovh_me_installation_template.debian: |-
                    {
                      "base_template_name": "debian11_64",
                      "customization": [
                        {
                          "ssh_key_name": "${ovh_me_ssh_key.key.key_name}"
                        }
                      ],
                      "default_language": "en",
                      "template_name": "mydebian11"
                    }
                ovh_me_ssh_key.key: |-
                    {
                      "key": "ssh-ed25519 AAAAC3...",
                      "key_name": "mykey"
                    }
        argumentDocs:
            bootid_on_destroy: '- If set, reboot the server on the specified boot id during destroy phase.'
            comment: '- Details of this task. (should be Install asked)'
            details: '- see details block below.'
            details.change_log: '- Template change log details.'
            details.custom_hostname: '- Set up the server using the provided hostname instead of the default hostname.'
            details.disk_group_id: '- Disk group id.'
            details.install_rtm: '- set to true to install RTM.'
            details.install_sql_server: '- set to true to install sql server (Windows template only).'
            details.language: '- language.'
            details.no_raid: '- set to true to disable RAID.'
            details.post_installation_script_link: '- Indicate the URL where your postinstall customisation script is located.'
            details.post_installation_script_return: '- Indicate the string returned by your postinstall customisation script on successful execution. Advice: your script should return a unique validation string in case of succes. A good example is ''loh1Xee7eo OK OK OK UGh8Ang1Gu''.'
            details.reset_hw_raid: '- set to true to make a hardware raid reset.'
            details.soft_raid_devices: '- soft raid devices.'
            details.ssh_key_name: '- Name of the ssh key that should be installed. Password login will be disabled.'
            details.use_distrib_kernel: '- Use the distribution''s native kernel instead of the recommended OVHcloud Kernel.'
            details.use_spla: '- set to true to use SPLA.'
            done_date: '- Completion date in RFC3339 format.'
            function: '- Function name (should be hardInstall).'
            id: '- The task id'
            last_update: '- Last update in RFC3339 format.'
            partition_scheme_name: '- Partition scheme name.'
            service_name: '- (Required) The service_name of your dedicated server.'
            start_date: '- Task creation date in RFC3339 format.'
            status: '- Task status (should be done)'
            template_name: '- (Required) Template name.'
        importStatements: []
    ovh_dedicated_server_networking:
        subCategory: ""
        name: ovh_dedicated_server_networking
        title: ""
        examples:
            - name: server
              manifest: |-
                {
                  "interfaces": [
                    {
                      "macs": "${sort(flatten(data.ovh_dedicated_server.server.vnis.*.nics))}",
                      "type": "vrack"
                    }
                  ],
                  "service_name": "${local.dedicated_server}"
                }
              references:
                service_name: local.dedicated_server
            - name: server
              manifest: |-
                {
                  "interfaces": [
                    {
                      "macs": "${slice(sort(flatten(data.ovh_dedicated_server.server.vnis.*.nics)), 0, 2)}",
                      "type": "vrack"
                    },
                    {
                      "macs": "${slice(sort(flatten(data.ovh_dedicated_server.server.vnis.*.nics)), 2, 4)}",
                      "type": "vrack"
                    }
                  ],
                  "service_name": "${local.dedicated_server}"
                }
              references:
                service_name: local.dedicated_server
        argumentDocs:
            description: '- Operation description.'
            interfaces: '- (Block List, Min: 1, Max: 2) Interface or interfaces aggregation.'
            macs: (List of String) List of mac addresses to bind together.
            service_name: '- (String) The service_name of your dedicated server. The full list of available dedicated servers can be found using the ovh_dedicated_servers datasource.'
            status: '- status of the networking configuration (should be active).'
            type: (String) Type of bonding to create.
        importStatements: []
    ovh_dedicated_server_reboot_task:
        subCategory: ""
        name: ovh_dedicated_server_reboot_task
        title: ""
        examples:
            - name: server_reboot
              manifest: |-
                {
                  "keepers": [
                    "${ovh_dedicated_server_update.server_on_rescue.boot_id}"
                  ],
                  "service_name": "${data.ovh_dedicated_server_boots.rescue.service_name}"
                }
              references:
                service_name: data.ovh_dedicated_server_boots.rescue.service_name
              dependencies:
                ovh_dedicated_server_update.server_on_rescue: |-
                    {
                      "boot_id": "${data.ovh_dedicated_server_boots.rescue.result[0]}",
                      "monitoring": true,
                      "service_name": "nsxxxxxxx.ip-xx-xx-xx.eu",
                      "state": "ok"
                    }
        argumentDocs:
            comment: '- Details of this task. (should be Reboot asked)'
            done_date: '- Completion date in RFC3339 format.'
            function: '- Function name (should be hardReboot).'
            id: '- The task id'
            keepers: '- List of values tracked to trigger reboot, used also to form implicit dependencies.'
            last_update: '- Last update in RFC3339 format.'
            service_name: '- (Required) The service_name of your dedicated server.'
            start_date: '- Task creation date in RFC3339 format.'
            status: '- Task status (should be done)'
        importStatements: []
    ovh_dedicated_server_update:
        subCategory: ""
        name: ovh_dedicated_server_update
        title: ""
        examples:
            - name: server
              manifest: |-
                {
                  "boot_id": "${data.ovh_dedicated_server_boots.rescue.result[0]}",
                  "monitoring": true,
                  "service_name": "nsxxxxxxx.ip-xx-xx-xx.eu",
                  "state": "ok"
                }
              references:
                boot_id: data.ovh_dedicated_server_boots.rescue.result[0]
        argumentDocs:
            boot_id: '- boot id of the server'
            monitoring: '- Icmp monitoring state'
            service_name: '- (Required) The service_name of your dedicated server.'
            state: '- error, hacked, hackedBlocked, ok'
        importStatements: []
    ovh_domain_zone:
        subCategory: ""
        name: ovh_domain_zone
        title: ""
        examples:
            - name: zone
              manifest: |-
                {
                  "ovh_subsidiary": "${data.ovh_order_cart.mycart.ovh_subsidiary}",
                  "plan": [
                    {
                      "configuration": [
                        {
                          "label": "zone",
                          "value": "myzone.mydomain.com"
                        },
                        {
                          "label": "template",
                          "value": "minimized"
                        }
                      ],
                      "duration": "${data.ovh_order_cart_product_plan.zone.selected_price.0.duration}",
                      "plan_code": "${data.ovh_order_cart_product_plan.zone.plan_code}",
                      "pricing_mode": "${data.ovh_order_cart_product_plan.zone.selected_price.0.pricing_mode}"
                    }
                  ]
                }
              references:
                ovh_subsidiary: data.ovh_order_cart.mycart.ovh_subsidiary
                plan.duration: data.ovh_order_cart_product_plan.zone.selected_price.0.duration
                plan.plan_code: data.ovh_order_cart_product_plan.zone.plan_code
                plan.pricing_mode: data.ovh_order_cart_product_plan.zone.selected_price.0.pricing_mode
        argumentDocs:
            catalog_name: '- Catalog name'
            configuration: '- (Optional) Representation of a configuration item for personalizing product'
            date: '- date'
            description: '- description'
            details: '- Information about a Bill entry'
            dnssec_supported: '- Is DNSSEC supported by this zone'
            domain: '- expiration date'
            duration: '- (Required) duration'
            expiration_date: '- expiration date'
            has_dns_anycast: '- hasDnsAnycast flag of the DNS zone'
            label: '- (Required) Identifier of the resource'
            last_update: '- Last update date of the DNS zone'
            name: '- Zone name'
            name_servers: '- Name servers that host the DNS zone'
            order: '- Details about an Order'
            order_detail_id: '- order detail id'
            order_id: '- order id'
            ovh_subsidiary: '- (Required) OVHcloud Subsidiary'
            plan: '- (Required) Product Plan to order'
            plan_code: '- (Required) Plan code'
            plan_option: '- (Optional) Product Plan to order'
            pricing_mode: '- (Required) Pricing model identifier'
            quantity: '- quantity'
            value: '- (Required) Path to the resource in API.OVH.COM'
        importStatements: []
    ovh_domain_zone_record:
        subCategory: ""
        name: ovh_domain_zone_record
        title: ""
        examples:
            - name: test
              manifest: |-
                {
                  "fieldtype": "A",
                  "subdomain": "test",
                  "target": "0.0.0.0",
                  "ttl": 3600,
                  "zone": "testdemo.ovh"
                }
        argumentDocs:
            fieldType: '- The type of the record'
            fieldtype: '- (Required) The type of the record'
            id: '- The record ID'
            subDomain: '- The name of the record'
            subdomain: '- (Required) The name of the record'
            target: '- (Required) The value of the record'
            ttl: '- (Optional) The TTL of the record, it shall be >= to 60.'
            zone: '- (Required) The domain to add the record to'
        importStatements: []
    ovh_domain_zone_redirection:
        subCategory: ""
        name: ovh_domain_zone_redirection
        title: ""
        examples:
            - name: test
              manifest: |-
                {
                  "subdomain": "test",
                  "target": "http://www.ovh",
                  "type": "visiblePermanent",
                  "zone": "testdemo.ovh"
                }
        argumentDocs:
            description: '- (Optional) A description of this redirection'
            id: '- The redirection ID'
            invisible: -> Redirection by html frame
            keywords: '- (Optional) Keywords to describe this redirection'
            subDomain: '- The name of the redirection'
            subdomain: '- (Optional) The name of the redirection'
            target: '- (Required) The value of the redirection'
            title: '- (Optional) Title of this redirection'
            type: '- (Required) The type of the redirection, with values:'
            visible: -> Redirection by http code 302
            visiblePermanent: -> Redirection by http code 301
            zone: '- (Required) The domain to add the redirection to'
        importStatements: []
    ovh_hosting_privatedatabase:
        subCategory: ""
        name: ovh_hosting_privatedatabase
        title: ""
        examples:
            - name: database
              manifest: |-
                {
                  "display_name": "Postgresql-12",
                  "ovh_subsidiary": "${data.ovh_order_cart.mycart.ovh_subsidiary}",
                  "plan": [
                    {
                      "configuration": [
                        {
                          "label": "dc",
                          "value": "gra3"
                        },
                        {
                          "label": "engine",
                          "value": "postgresql_12"
                        }
                      ],
                      "duration": "${data.ovh_order_cart_product_plan.database.prices[3].duration}",
                      "plan_code": "${data.ovh_order_cart_product_plan.database.plan_code}",
                      "pricing_mode": "${data.ovh_order_cart_product_plan.database.selected_price[0].pricing_mode}"
                    }
                  ]
                }
              references:
                ovh_subsidiary: data.ovh_order_cart.mycart.ovh_subsidiary
                plan.duration: data.ovh_order_cart_product_plan.database.prices[3].duration
                plan.plan_code: data.ovh_order_cart_product_plan.database.plan_code
                plan.pricing_mode: data.ovh_order_cart_product_plan.database.selected_price[0].pricing_mode
        argumentDocs:
            catalog_name: '- Catalog name'
            configuration: '- (Optional) Representation of a configuration item for personalizing product'
            cpu: '- Number of CPU on your private database'
            datacenter: '- Datacenter where this private database is located'
            date: '- date'
            description: '- Custom description on your privatedatabase order.'
            details: '- Information about a Bill entry'
            display_name: '- Name displayed in customer panel for your private database'
            domain: '- expiration date'
            duration: '- (Required) duration.'
            expiration_date: '- expiration date'
            hostname: '- Private database hostname'
            hostname_ftp: '- Private database FTP hostname'
            id: '- Private database id'
            infrastructure: '- Infrastructure where service was stored'
            label: '- (Required) Identifier of the resource'
            offer: '- Type of the private database offer'
            order: '- Details about your Order'
            order_detail_id: '- order detail id'
            order_id: '- order id'
            ovh_subsidiary: '- (Required) OVHcloud Subsidiary'
            plan: '- (Required) Product Plan to order'
            plan_code: '- (Required) Plan code.'
            plan_option: ': Product Plan to order'
            port: ': Private database service port'
            port_ftp: ': Private database FTP port'
            pricing_mode: '- (Required) Pricing model identifier'
            quantity: '- quantity'
            quota_size: ': Space allowed (in MB) on your private database'
            quota_used: ': Sapce used (in MB) on your private database'
            ram: ': Amount of ram (in MB) on your private database'
            server: ': Private database server name'
            service_name: ': Service name'
            state: ': Private database state'
            type: ': Private database type'
            value: '- (Required) Path to the resource in API.OVH.COM'
            version: ': Private database available versions'
            version_label: ': Private database version label'
            version_number: ': Private database version number'
        importStatements: []
    ovh_hosting_privatedatabase_database:
        subCategory: ""
        name: ovh_hosting_privatedatabase_database
        title: ""
        examples:
            - name: database
              manifest: |-
                {
                  "database_name": "XXXXXX",
                  "service_name": "XXXXXX"
                }
        argumentDocs:
            database_name: '- (Required) Name of your new database'
            service_name: '- The internal name of your private database.'
        importStatements: []
    ovh_hosting_privatedatabase_user:
        subCategory: ""
        name: ovh_hosting_privatedatabase_user
        title: ""
        examples:
            - name: user
              manifest: |-
                {
                  "password": "XXXXXX",
                  "service_name": "XXXXXX",
                  "user_name": "XXXXXX"
                }
        argumentDocs:
            password: '- (Required) Password for the new user (alphanumeric, minimum one number and 8 characters minimum)'
            service_name: '- The internal name of your private database.'
            user_name: '- (Required) User name used to connect on your databases'
        importStatements: []
    ovh_hosting_privatedatabase_user_grant:
        subCategory: ""
        name: ovh_hosting_privatedatabase_user_grant
        title: ""
        examples:
            - name: user_grant
              manifest: |-
                {
                  "database_name": "ovhcloud",
                  "grant": "admin",
                  "service_name": "XXXXXX",
                  "user_name": "terraform"
                }
        argumentDocs:
            database_name: '- (Required) Database name where add grant.'
            grant: '- (Required) Database name where add grant. Values can be:'
            service_name: '- The internal name of your private database.'
            user_name: '- (Required) User name used to connect on your databases.'
        importStatements: []
    ovh_hosting_privatedatabase_whitelist:
        subCategory: ""
        name: ovh_hosting_privatedatabase_whitelist
        title: ""
        examples:
            - name: ip
              manifest: |-
                {
                  "ip": "1.2.3.4",
                  "name": "A name for your IP address",
                  "service": true,
                  "service_name": "XXXXXX",
                  "sftp": true
                }
        argumentDocs:
            ip: '- (Required) The whitelisted IP in your instance.'
            name: '- (Required) Custom name for your Whitelisted IP.'
            service: '- (Required) Authorize this IP to access service port. Values can be true or false'
            service_name: '- The internal name of your private database.'
            sftp: '- (Required) Authorize this IP to access SFTP port. Values can be true or false'
        importStatements: []
    ovh_ip_reverse:
        subCategory: ""
        name: ovh_ip_reverse
        title: ""
        examples:
            - name: test
              manifest: |-
                {
                  "ip": "192.0.2.0/24",
                  "ip_reverse": "192.0.2.1",
                  "reverse": "example.com"
                }
        argumentDocs:
            ip: '- (Required) The IP block to which the IP belongs'
            ip_reverse: '- (Required) The IP to set the reverse of'
            reverse: '- (Required) The value of the reverse'
        importStatements: []
    ovh_ip_service:
        subCategory: ""
        name: ovh_ip_service
        title: ""
        examples:
            - name: ipblock
              manifest: |-
                {
                  "description": "${data.ovh_order_cart.mycart.description}",
                  "ovh_subsidiary": "${data.ovh_order_cart.mycart.ovh_subsidiary}",
                  "plan": [
                    {
                      "configuration": [
                        {
                          "label": "country",
                          "value": "FR"
                        }
                      ],
                      "duration": "${data.ovh_order_cart_product_plan.ipblock.selected_price.0.duration}",
                      "plan_code": "${data.ovh_order_cart_product_plan.ipblock.plan_code}",
                      "pricing_mode": "${data.ovh_order_cart_product_plan.ipblock.selected_price.0.pricing_mode}"
                    }
                  ]
                }
              references:
                description: data.ovh_order_cart.mycart.description
                ovh_subsidiary: data.ovh_order_cart.mycart.ovh_subsidiary
                plan.duration: data.ovh_order_cart_product_plan.ipblock.selected_price.0.duration
                plan.plan_code: data.ovh_order_cart_product_plan.ipblock.plan_code
                plan.pricing_mode: data.ovh_order_cart_product_plan.ipblock.selected_price.0.pricing_mode
              dependencies:
                ovh_vrack.vrack: |-
                    {
                      "description": "${data.ovh_order_cart.mycart.description}",
                      "name": "${data.ovh_order_cart.mycart.description}",
                      "ovh_subsidiary": "${data.ovh_order_cart.mycart.ovh_subsidiary}",
                      "plan": [
                        {
                          "duration": "${data.ovh_order_cart_product_plan.vrack.selected_price.0.duration}",
                          "plan_code": "${data.ovh_order_cart_product_plan.vrack.plan_code}",
                          "pricing_mode": "${data.ovh_order_cart_product_plan.vrack.selected_price.0.pricing_mode}"
                        }
                      ]
                    }
                ovh_vrack_ip.vrackblock: |-
                    {
                      "block": "${ovh_ip_service.ipblock.ip}",
                      "service_name": "${ovh_vrack.vrack.service_name}"
                    }
        argumentDocs:
            block: '- (Required) Your IP block.'
            gateway: '- Your gateway'
            ip: '- Your IP block'
            service_name: '- (Required) The internal name of your vrack'
            zone: '- Where you want your block announced on the network'
        importStatements: []
    ovh_iploadbalancing:
        subCategory: ""
        name: ovh_iploadbalancing
        title: ""
        examples:
            - name: iplb-lb1
              manifest: |-
                {
                  "display_name": "my ip loadbalancing",
                  "ovh_subsidiary": "${data.ovh_order_cart.mycart.ovh_subsidiary}",
                  "plan": [
                    {
                      "duration": "${data.ovh_order_cart_product_plan.iplb.selected_price.0.duration}",
                      "plan_code": "${data.ovh_order_cart_product_plan.iplb.plan_code}",
                      "pricing_mode": "${data.ovh_order_cart_product_plan.iplb.selected_price.0.pricing_mode}"
                    }
                  ],
                  "plan_option": [
                    {
                      "duration": "${data.ovh_order_cart_product_options_plan.bhs.selected_price.0.duration}",
                      "plan_code": "${data.ovh_order_cart_product_options_plan.bhs.plan_code}",
                      "pricing_mode": "${data.ovh_order_cart_product_options_plan.bhs.selected_price.0.pricing_mode}"
                    }
                  ]
                }
              references:
                ovh_subsidiary: data.ovh_order_cart.mycart.ovh_subsidiary
                plan.duration: data.ovh_order_cart_product_plan.iplb.selected_price.0.duration
                plan.plan_code: data.ovh_order_cart_product_plan.iplb.plan_code
                plan.pricing_mode: data.ovh_order_cart_product_plan.iplb.selected_price.0.pricing_mode
                plan_option.duration: data.ovh_order_cart_product_options_plan.bhs.selected_price.0.duration
                plan_option.plan_code: data.ovh_order_cart_product_options_plan.bhs.plan_code
                plan_option.pricing_mode: data.ovh_order_cart_product_options_plan.bhs.selected_price.0.pricing_mode
        argumentDocs:
            catalog_name: '- Catalog name'
            configuration: '- (Optional) Representation of a configuration item for personalizing product'
            date: '- date'
            description: '- description'
            details: '- Information about a Bill entry'
            display_name: '- Set the name displayed in ManagerV6 for your iplb (max 50 chars)'
            domain: '- expiration date'
            duration: '- (Required) duration'
            expiration_date: '- expiration date'
            ip_loadbalancing: '- Your IP load balancing'
            ipv4: '- The IPV4 associated to your IP load balancing'
            ipv6: '- The IPV6 associated to your IP load balancing. DEPRECATED.'
            label: '- (Required) Identifier of the resource'
            metrics_token: '- The metrics token associated with your IP load balancing'
            name: '- The zone three letter code'
            offer: '- The offer of your IP load balancing'
            order: '- Details about an Order'
            order_detail_id: '- order detail id'
            order_id: '- order id'
            orderable_zone: '- Available additional zone for your Load Balancer'
            ovh_subsidiary: '- (Required) OVHcloud Subsidiary'
            plan: '- (Required) Product Plan to order'
            plan_code: '- (Required) Plan code'
            plan_option: '- (Optional) Product Plan to order'
            pricing_mode: '- (Required) Pricing model identifier'
            quantity: '- quantity'
            service_name: '- The internal name of your IP load balancing'
            ssl_configuration: '- Modern oldest compatible clients : Firefox 27, Chrome 30, IE 11 on Windows 7, Edge, Opera 17, Safari 9, Android 5.0, and Java 8. Intermediate oldest compatible clients : Firefox 1, Chrome 1, IE 7, Opera 5, Safari 1, Windows XP IE8, Android 2.3, Java 7. Intermediate if null. one of "intermediate", "modern".'
            state: '- Current state of your IP'
            value: '- (Required) Path to the resource in API.OVH.COM'
            vrack_eligibility: '- Vrack eligibility'
            vrack_name: '- Name of the vRack on which the current Load Balancer is attached to, as it is named on vRack product'
            zone: '- Location where your service is'
        importStatements: []
    ovh_iploadbalancing_http_farm:
        subCategory: ""
        name: ovh_iploadbalancing_http_farm
        title: ""
        examples:
            - name: farmname
              manifest: |-
                {
                  "display_name": "ingress-8080-gra",
                  "service_name": "${data.ovh_iploadbalancing.lb.service_name}",
                  "zone": "GRA"
                }
        argumentDocs:
            balance: '- Load balancing algorithm. roundrobin if null (first, leastconn, roundrobin, source)'
            display_name: '- Readable label for loadbalancer farm'
            force_ssl: '- Force use of SSL (TLS)'
            interval: '- probe interval, Value between 30 and 3600 seconds, default 30'
            match: '- What to match pattern against (contains, default, internal, matches, status)'
            method: '- HTTP probe method (GET, HEAD, OPTIONS, internal)'
            negate: '- Negate probe result'
            pattern: '- Pattern to match against match'
            port: '- Port attached to your farm ([1..49151]). Inherited from frontend if null'
            probe: '- define a backend healthcheck probe'
            service_name: '- (Required) The internal name of your IP load balancing'
            stickiness: "- \tStickiness type. No stickiness if null (sourceIp, cookie)"
            type: '- (Required) Valid values : http, internal, mysql, oco, pgsql, smtp, tcp'
            url: '- URL for HTTP probe type.'
            vrack_network_id: '- Internal Load Balancer identifier of the vRack private network to attach to your farm, mandatory when your Load Balancer is attached to a vRack'
            zone: '- (Required) Zone where the farm will be defined (ie. GRA, BHS also supports ALL)'
        importStatements: []
    ovh_iploadbalancing_http_farm_server:
        subCategory: ""
        name: ovh_iploadbalancing_http_farm_server
        title: ""
        examples:
            - name: backend
              manifest: |-
                {
                  "address": "4.5.6.7",
                  "backup": true,
                  "display_name": "mybackend",
                  "farm_id": "${ovh_iploadbalancing_http_farm.farmname.id}",
                  "port": 80,
                  "probe": true,
                  "proxy_protocol_version": "v2",
                  "service_name": "${data.ovh_iploadbalancing.lb.service_name}",
                  "ssl": false,
                  "status": "active",
                  "weight": 2
                }
              dependencies:
                ovh_iploadbalancing_http_farm.farmname: |-
                    {
                      "port": 8080,
                      "service_name": "${data.ovh_iploadbalancing.lb.service_name}",
                      "zone": "all"
                    }
        argumentDocs:
            address: '- Address of the backend server (IP from either internal or OVHcloud network)'
            backup: '- is it a backup server used in case of failure of all the non-backup backends'
            cookie: '- Value of the stickiness cookie used for this backend.'
            display_name: '- Label for the server'
            farm_id: '- ID of the farm this server is attached to'
            on_marked_down: '- enable action when backend marked down. (shutdown-sessions)'
            port: '- Port that backend will respond on'
            probe: '- defines if backend will be probed to determine health and keep as active in farm if healthy'
            proxy_protocol_version: '- version of the PROXY protocol used to pass origin connection information from loadbalancer to receiving service (v1, v2, v2-ssl, v2-ssl-cn)'
            service_name: '- (Required) The internal name of your IP load balancing'
            ssl: '- is the connection ciphered with SSL (TLS)'
            status: '- backend status - active or inactive'
            weight: '- used in loadbalancing algorithm'
        importStatements: []
    ovh_iploadbalancing_http_frontend:
        subCategory: ""
        name: ovh_iploadbalancing_http_frontend
        title: ""
        examples:
            - name: testfrontend
              manifest: |-
                {
                  "default_farm_id": "${ovh_iploadbalancing_http_farm.farm80.id}",
                  "display_name": "ingress-8080-gra",
                  "port": "80,443",
                  "service_name": "${data.ovh_iploadbalancing.lb.service_name}",
                  "zone": "all"
                }
              dependencies:
                ovh_iploadbalancing_http_farm.farm80: |-
                    {
                      "display_name": "ingress-8080-gra",
                      "port": 80,
                      "service_name": "${data.ovh_iploadbalancing.lb.service_name}",
                      "zone": "all"
                    }
        argumentDocs:
            allowed_source: '- Restrict IP Load Balancing access to these ip block. No restriction if null. List of IP blocks.'
            dedicated_ipfo: '- Only attach frontend on these ip. No restriction if null. List of Ip blocks.'
            default_farm_id: '- Default TCP Farm of your frontend'
            default_ssl_id: '- Default ssl served to your customer'
            disabled: '- Disable your frontend. Default: ''false'''
            display_name: '- Human readable name for your frontend, this field is for you'
            hsts: '- HTTP Strict Transport Security. Default: ''false'''
            http_header: '- HTTP headers to add to the frontend. List of string.'
            id: '- Id of your frontend'
            port: |-
                - Port(s) attached to your frontend. Supports single port (numerical value),
                range (2 dash-delimited increasing ports) and comma-separated list of 'single port'
                and/or 'range'. Each port must be in the [1;49151] range
            redirect_location: '- Redirection HTTP'''
            service_name: '- (Required) The internal name of your IP load balancing'
            ssl: '- SSL deciphering. Default: ''false'''
            zone: '- (Required) Zone where the frontend will be defined (ie. gra, bhs also supports all)'
        importStatements: []
    ovh_iploadbalancing_http_route:
        subCategory: ""
        name: ovh_iploadbalancing_http_route
        title: ""
        examples:
            - name: httpsredirect
              manifest: |-
                {
                  "action": [
                    {
                      "status": 302,
                      "target": "https://${host}${path}${arguments}",
                      "type": "redirect"
                    }
                  ],
                  "display_name": "Redirect to HTTPS",
                  "service_name": "loadbalancer-xxxxxxxxxxxxxxxxxx",
                  "weight": 1
                }
        argumentDocs:
            action: '- (Required) Action triggered when all rules match'
            display_name: '- Human readable name for your route, this field is for you'
            field: '- Name of the field to match like "protocol" or "host" "/ipLoadbalancing/{serviceName}/route/availableRules" for a list of available rules'
            frontend_id: '- Route traffic for this frontend'
            match: '- Matching operator. Not all operators are available for all fields. See "availableRules"'
            negate: '- Invert the matching operator effect'
            pattern: '- Value to match against this match. Interpretation if this field depends on the match and field'
            rule_id: '- Id of your rule'
            rules: '- List of rules to match to trigger action'
            service_name: '- (Required) The internal name of your IP load balancing'
            status: '- HTTP status code for "redirect" and "reject" actions'
            sub_field: '- Name of sub-field, if applicable. This may be a Cookie or Header name for instance'
            target: '- Farm ID for "farm" action type or URL template for "redirect" action. You may use ${uri}, ${protocol}, ${host}, ${port} and ${path} variables in redirect target'
            type: '- (Required) Action to trigger if all the rules of this route matches'
            weight: '- Route priority ([0..255]). 0 if null. Highest priority routes are evaluated first. Only the first matching route will trigger an action'
        importStatements: []
    ovh_iploadbalancing_http_route_rule:
        subCategory: ""
        name: ovh_iploadbalancing_http_route_rule
        title: ""
        examples:
            - name: examplerule
              manifest: |-
                {
                  "display_name": "Match example.com host",
                  "field": "host",
                  "match": "is",
                  "negate": false,
                  "pattern": "example.com",
                  "route_id": "${ovh_iploadbalancing_http_route.httpsredirect.id}",
                  "service_name": "loadbalancer-xxxxxxxxxxxxxxxxxx"
                }
              dependencies:
                ovh_iploadbalancing_http_route.httpsredirect: |-
                    {
                      "action": [
                        {
                          "status": 302,
                          "target": "https://${host}${path}${arguments}",
                          "type": "redirect"
                        }
                      ],
                      "display_name": "Redirect to HTTPS",
                      "frontend_id": 11111,
                      "service_name": "loadbalancer-xxxxxxxxxxxxxxxxxx",
                      "weight": 1
                    }
            - name: examplerule
              manifest: |-
                {
                  "display_name": "Match example.com Host header",
                  "field": "headers",
                  "match": "is",
                  "negate": false,
                  "pattern": "example.com",
                  "route_id": "${ovh_iploadbalancing_http_route.httpsredirect.id}",
                  "service_name": "loadbalancer-xxxxxxxxxxxxxxxxxx",
                  "sub_field": "Host"
                }
        argumentDocs:
            display_name: '- Human readable name for your rule, this field is for you'
            field: '- (Required) Name of the field to match like "protocol" or "host". See "/ipLoadbalancing/{serviceName}/availableRouteRules" for a list of available rules'
            match: '- (Required) Matching operator. Not all operators are available for all fields. See "/ipLoadbalancing/{serviceName}/availableRouteRules"'
            negate: '- Invert the matching operator effect'
            pattern: '- Value to match against this match. Interpretation if this field depends on the match and field'
            route_id: '- (Required) The route to apply this rule'
            service_name: '- (Required) The internal name of your IP load balancing'
            sub_field: '- Name of sub-field, if applicable. This may be a Cookie or Header name for instance'
        importStatements: []
    ovh_iploadbalancing_refresh:
        subCategory: ""
        name: ovh_iploadbalancing_refresh
        title: ""
        examples:
            - name: mylb
              manifest: |-
                {
                  "keepers": [
                    "${ovh_iploadbalancing_tcp_farm_server.backend.*.address}"
                  ],
                  "service_name": "${data.ovh_iploadbalancing.lb.service_name}"
                }
              dependencies:
                ovh_iploadbalancing_tcp_farm.farmname: |-
                    {
                      "port": 8080,
                      "service_name": "${data.ovh_iploadbalancing.lb.service_name}",
                      "zone": "all"
                    }
                ovh_iploadbalancing_tcp_farm_server.backend: |-
                    {
                      "address": "4.5.6.7",
                      "backup": true,
                      "display_name": "mybackend",
                      "farm_id": "${ovh_iploadbalancing_tcp_farm.farmname.id}",
                      "port": 80,
                      "probe": true,
                      "proxy_protocol_version": "v2",
                      "service_name": "${data.ovh_iploadbalancing.lb.service_name}",
                      "ssl": false,
                      "status": "active",
                      "weight": 2
                    }
        argumentDocs:
            keepers: '- List of values tracked to trigger refresh, used also to form implicit dependencies'
            service_name: '- (Required) The internal name of your IP load balancing'
        importStatements: []
    ovh_iploadbalancing_tcp_farm:
        subCategory: ""
        name: ovh_iploadbalancing_tcp_farm
        title: ""
        examples:
            - name: farmname
              manifest: |-
                {
                  "display_name": "ingress-8080-gra",
                  "service_name": "${data.ovh_iploadbalancing.lb.service_name}",
                  "zone": "GRA"
                }
        argumentDocs:
            balance: '- Load balancing algorithm. roundrobin if null (first, leastconn, roundrobin, source)'
            display_name: '- Readable label for loadbalancer farm'
            force_ssl: '- Force use of SSL (TLS)'
            interval: '- probe interval, Value between 30 and 3600 seconds, default 30'
            match: '- What to match pattern against (contains, default, internal, matches, status)'
            method: '- HTTP probe method (GET, HEAD, OPTIONS, internal)'
            negate: '- Negate probe result'
            pattern: '- Pattern to match against match'
            port: '- Port attached to your farm ([1..49151]). Inherited from frontend if null'
            probe: '- define a backend healthcheck probe'
            service_name: '- (Required) The internal name of your IP load balancing'
            stickiness: "- \tStickiness type. No stickiness if null (sourceIp)"
            type: '- (Required) Valid values : http, internal, mysql, oco, pgsql, smtp, tcp'
            url: '- URL for HTTP probe type.'
            vrack_network_id: '- Internal Load Balancer identifier of the vRack private network to attach to your farm, mandatory when your Load Balancer is attached to a vRack'
            zone: '- (Required) Zone where the farm will be defined (ie. GRA, BHS also supports ALL)'
        importStatements: []
    ovh_iploadbalancing_tcp_farm_server:
        subCategory: ""
        name: ovh_iploadbalancing_tcp_farm_server
        title: ""
        examples:
            - name: backend
              manifest: |-
                {
                  "address": "4.5.6.7",
                  "backup": true,
                  "display_name": "mybackend",
                  "farm_id": "${ovh_iploadbalancing_tcp_farm.farmname.id}",
                  "port": 80,
                  "probe": true,
                  "proxy_protocol_version": "v2",
                  "service_name": "${data.ovh_iploadbalancing.lb.service_name}",
                  "ssl": false,
                  "status": "active",
                  "weight": 2
                }
              dependencies:
                ovh_iploadbalancing_tcp_farm.farmname: |-
                    {
                      "port": 8080,
                      "service_name": "${data.ovh_iploadbalancing.lb.service_name}",
                      "zone": "all"
                    }
        argumentDocs:
            address: '- Address of the backend server (IP from either internal or OVHcloud network)'
            backup: '- is it a backup server used in case of failure of all the non-backup backends'
            cookie: '- Value of the stickiness cookie used for this backend.'
            display_name: '- Label for the server'
            farm_id: '- ID of the farm this server is attached to'
            on_marked_down: '- enable action when backend marked down. (shutdown-sessions)'
            port: '- Port that backend will respond on'
            probe: '- defines if backend will be probed to determine health and keep as active in farm if healthy'
            proxy_protocol_version: '- version of the PROXY protocol used to pass origin connection information from loadbalancer to receiving service (v1, v2, v2-ssl, v2-ssl-cn)'
            service_name: '- (Required) The internal name of your IP load balancing'
            ssl: '- is the connection ciphered with SSL (TLS)'
            status: '- backend status - active or inactive'
            weight: '- used in loadbalancing algorithm'
        importStatements: []
    ovh_iploadbalancing_tcp_frontend:
        subCategory: ""
        name: ovh_iploadbalancing_tcp_frontend
        title: ""
        examples:
            - name: testfrontend
              manifest: |-
                {
                  "default_farm_id": "${ovh_iploadbalancing_tcp_farm.farm80.id}",
                  "display_name": "ingress-8080-gra",
                  "port": "80,443",
                  "service_name": "${data.ovh_iploadbalancing.lb.service_name}",
                  "zone": "all"
                }
              dependencies:
                ovh_iploadbalancing_tcp_farm.farm80: |-
                    {
                      "display_name": "ingress-8080-gra",
                      "port": 80,
                      "service_name": "${data.ovh_iploadbalancing.lb.service_name}",
                      "zone": "all"
                    }
        argumentDocs:
            allowed_source: '- Restrict IP Load Balancing access to these ip block. No restriction if null. List of IP blocks.'
            dedicated_ipfo: '- Only attach frontend on these ip. No restriction if null. List of Ip blocks.'
            default_farm_id: '- Default TCP Farm of your frontend'
            default_ssl_id: '- Default ssl served to your customer'
            disabled: '- Disable your frontend. Default: ''false'''
            display_name: '- Human readable name for your frontend, this field is for you'
            id: '- Id of your frontend'
            port: |-
                - Port(s) attached to your frontend. Supports single port (numerical value),
                range (2 dash-delimited increasing ports) and comma-separated list of 'single port'
                and/or 'range'. Each port must be in the [1;49151] range
            service_name: '- (Required) The internal name of your IP load balancing'
            ssl: '- SSL deciphering. Default: ''false'''
            zone: '- (Required) Zone where the frontend will be defined (ie. gra, bhs also supports all)'
        importStatements: []
    ovh_iploadbalancing_tcp_route:
        subCategory: ""
        name: ovh_iploadbalancing_tcp_route
        title: ""
        examples:
            - name: tcpreject
              manifest: |-
                {
                  "action": [
                    {
                      "type": "reject"
                    }
                  ],
                  "service_name": "loadbalancer-xxxxxxxxxxxxxxxxxx",
                  "weight": 1
                }
        argumentDocs:
            action: '- (Required) Action triggered when all rules match'
            display_name: '- Human readable name for your route, this field is for you'
            field: '- Name of the field to match like "protocol" or "host" "/ipLoadbalancing/{serviceName}/route/availableRules" for a list of available rules'
            frontend_id: '- Route traffic for this frontend'
            match: '- Matching operator. Not all operators are available for all fields. See "availableRules"'
            negate: '- Invert the matching operator effect'
            pattern: '- Value to match against this match. Interpretation if this field depends on the match and field'
            rule_id: '- Id of your rule'
            rules: '- List of rules to match to trigger action'
            service_name: '- (Required) The internal name of your IP load balancing'
            status: '- Route status. Routes in "ok" state are ready to operate'
            sub_field: '- Name of sub-field, if applicable. This may be a Cookie or Header name for instance'
            target: '- Farm ID for "farm" action type, empty for others.'
            type: '- (Required) Action to trigger if all the rules of this route matches'
            weight: '- Route priority ([0..255]). 0 if null. Highest priority routes are evaluated first. Only the first matching route will trigger an action'
        importStatements: []
    ovh_iploadbalancing_tcp_route_rule:
        subCategory: ""
        name: ovh_iploadbalancing_tcp_route_rule
        title: ""
        examples:
            - name: examplerule
              manifest: |-
                {
                  "display_name": "Match example.com host",
                  "field": "sni",
                  "match": "is",
                  "negate": false,
                  "pattern": "example.com",
                  "route_id": "${ovh_iploadbalancing_tcp_route.reject.id}",
                  "service_name": "loadbalancer-xxxxxxxxxxxxxxxxxx"
                }
              references:
                route_id: ovh_iploadbalancing_tcp_route.reject.id
              dependencies:
                ovh_iploadbalancing_tcp_route.reject: |-
                    {
                      "action": [
                        {
                          "type": "reject"
                        }
                      ],
                      "frontend_id": 11111,
                      "service_name": "loadbalancer-xxxxxxxxxxxxxxxxxx",
                      "weight": 1
                    }
        argumentDocs:
            display_name: '- Human readable name for your rule, this field is for you'
            field: '- (Required) Name of the field to match like "protocol" or "host". See "/ipLoadbalancing/{serviceName}/availableRouteRules" for a list of available rules'
            match: '- (Required) Matching operator. Not all operators are available for all fields. See "/ipLoadbalancing/{serviceName}/availableRouteRules"'
            negate: '- Invert the matching operator effect'
            pattern: '- Value to match against this match. Interpretation if this field depends on the match and field'
            route_id: '- (Required) The route to apply this rule'
            service_name: '- (Required) The internal name of your IP load balancing'
            sub_field: '- Name of sub-field, if applicable. This may be a Cookie or Header name for instance'
        importStatements: []
    ovh_iploadbalancing_vrack_network:
        subCategory: ""
        name: ovh_iploadbalancing_vrack_network
        title: ""
        examples:
            - name: network
              manifest: |-
                {
                  "display_name": "mynetwork",
                  "nat_ip": "10.0.0.0/27",
                  "service_name": "${ovh_vrack_iploadbalancing.viplb.ip_loadbalancing}",
                  "subnet": "10.0.0.0/16",
                  "vlan": 1
                }
              references:
                service_name: ovh_vrack_iploadbalancing.viplb.ip_loadbalancing
              dependencies:
                ovh_iploadbalancing_tcp_farm.testfarm: |-
                    {
                      "display_name": "mytcpbackends",
                      "port": 80,
                      "service_name": "${ovh_iploadbalancing_vrack_network.network.service_name}",
                      "vrack_network_id": "${ovh_iploadbalancing_vrack_network.network.vrack_network_id}",
                      "zone": "${tolist(data.ovh_iploadbalancing.iplb.zone)[0]}"
                    }
                ovh_vrack_iploadbalancing.viplb: |-
                    {
                      "ip_loadbalancing": "${data.ovh_iploadbalancing.iplb.service_name}",
                      "service_name": "xxx"
                    }
        argumentDocs:
            display_name: '- Human readable name for your vrack network'
            farm_id: '- This attribute is there for documentation purpose only and isnt passed to the OVHcloud API as it may conflicts with http/tcp farms vrack_network_id attribute'
            nat_ip: '- (Required) An IP block used as a pool of IPs by this Load Balancer to connect to the servers in this private network. The blck must be in the private network and reserved for the Load Balancer'
            service_name: '- (Required) The internal name of your IP load balancing'
            subnet: '- (Required) IP block of the private network in the vRack'
            vlan: '- VLAN of the private network in the vRack. 0 if the private network is not in a VLAN'
            vrack_network_id: '- (Required) Internal Load Balancer identifier of the vRack private network'
        importStatements: []
    ovh_me_identity_group:
        subCategory: ""
        name: ovh_me_identity_group
        title: ""
        examples:
            - name: my_group
              manifest: |-
                {
                  "description": "Some custom description",
                  "name": "my_group_name",
                  "role": "NONE"
                }
        argumentDocs:
            creation: '- Creation date of this group.'
            default_group: '- Is the group a default and immutable one.'
            description: '- Group description.'
            last_update: '- Date of the last update of this group.'
            name: '- Group name.'
            role: '- Role associated with the group. Valid roles are ADMIN, REGULAR, UNPRIVILEGED, and NONE.'
        importStatements: []
    ovh_me_identity_user:
        subCategory: ""
        name: ovh_me_identity_user
        title: ""
        examples:
            - name: my_user
              manifest: |-
                {
                  "description": "Some custom description",
                  "email": "my_login@example.com",
                  "group": "DEFAULT",
                  "login": "my_login",
                  "password": "super-s3cr3t!password"
                }
        argumentDocs:
            creation: '- Creation date of this user.'
            description: '- User description.'
            email: '- User''s email.'
            group: '- User''s group.'
            last_update: '- Last update of this user.'
            login: '- User''s login suffix.'
            password: '- User''s password.'
            password_last_update: '- When the user changed his password for the last time.'
            status: '- Current user''s status.'
        importStatements: []
    ovh_me_installation_template:
        subCategory: ""
        name: ovh_me_installation_template
        title: ""
        examples:
            - name: mytemplate
              manifest: |-
                {
                  "base_template_name": "centos7_64",
                  "default_language": "en",
                  "template_name": "mytemplate"
                }
        argumentDocs:
            available_languages: ': List of all language available for this template.'
            base_template_name: ': (Required) The name of an existing installation template, choose one among the list given by ovh_dedicated_installation_templates datasource.'
            beta: ': This distribution is new and, although tested and functional, may still display odd behaviour.'
            bit_format: ': This template bit format (32 or 64).'
            category: ': Category of this template (informative only). (basic, customer, hosting, other, readyToUse, virtualisation).'
            change_log: ': (DEPRECATED) Template change log details.'
            custom_hostname: ': Set up the server using the provided hostname instead of the default hostname.'
            customization: ':'
            default_language: ': (Required)  The default language of this template.'
            deprecated: ': is this distribution deprecated.'
            description: ': information about this template.'
            distribution: ': the distribution this template is based on.'
            family: ': this template family type (bsd,linux,solaris,windows).'
            filesystems: ': Filesystems available (btrfs,ext3,ext4,ntfs,reiserfs,swap,ufs,xfs,zfs).'
            hard_raid_configuration: ': This distribution supports hardware raid configuration through the OVHcloud API.'
            id: ': This template name.'
            last_modification: ': Date of last modification of the base image.'
            post_installation_script_link: ': Indicate the URL where your postinstall customisation script is located.'
            post_installation_script_return: ': indicate the string returned by your postinstall customisation script on successful execution. Advice: your script should return a unique validation string in case of succes. A good example is ''loh1Xee7eo OK OK OK UGh8Ang1Gu''.'
            rating: ': (DEPRECATED) Rating.'
            remove_default_partition_schemes: ': (Required) Remove default partition schemes at creation.'
            ssh_key_name: ': Name of the ssh key that should be installed. Password login will be disabled.'
            supports_distribution_kernel: ': This distribution supports installation using the distribution''s native kernel instead of the recommended OVHcloud kernel.'
            supports_rtm: ': This distribution supports RTM software.'
            supports_sql_server: ': This distribution supports the microsoft SQL server.'
            template_name: ': (Required)  This template name.'
            use_distribution_kernel: ': Use the distribution''s native kernel instead of the recommended OV'
        importStatements: []
    ovh_me_installation_template_partition_scheme:
        subCategory: ""
        name: ovh_me_installation_template_partition_scheme
        title: ""
        examples:
            - name: scheme
              manifest: |-
                {
                  "name": "myscheme",
                  "priority": 1,
                  "template_name": "${ovh_me_installation_template.mytemplate.template_name}"
                }
              references:
                template_name: ovh_me_installation_template.mytemplate.template_name
              dependencies:
                ovh_me_installation_template.mytemplate: |-
                    {
                      "base_template_name": "centos7_64",
                      "default_language": "fr",
                      "template_name": "mytemplate"
                    }
        argumentDocs:
            id: ': a fake id associated with this partition scheme formatted as follow: template_name/name'
            name: ': (Required) (Required) This partition scheme name.'
            priority: ': on a reinstall, if a partitioning scheme is not specified, the one with the higher priority will be used by default, among all the compatible partitioning schemes (given the underlying hardware specifications).'
            template_name: ': (Required) The template name of the partition scheme.'
        importStatements: []
    ovh_me_installation_template_partition_scheme_hardware_raid:
        subCategory: ""
        name: ovh_me_installation_template_partition_scheme_hardware_raid
        title: ""
        examples:
            - name: group1
              manifest: |-
                {
                  "disks": [
                    "[c1:d1,c1:d2,c1:d3]",
                    "[c1:d10,c1:d20,c1:d30]"
                  ],
                  "mode": "raid50",
                  "name": "group1",
                  "scheme_name": "${ovh_me_installation_template_partition_scheme.scheme.name}",
                  "step": 1,
                  "template_name": "${ovh_me_installation_template_partition_scheme.scheme.template_name}"
                }
              references:
                scheme_name: ovh_me_installation_template_partition_scheme.scheme.name
                template_name: ovh_me_installation_template_partition_scheme.scheme.template_name
              dependencies:
                ovh_me_installation_template.mytemplate: |-
                    {
                      "base_template_name": "centos7_64",
                      "default_language": "fr",
                      "template_name": "mytemplate"
                    }
                ovh_me_installation_template_partition_scheme.scheme: |-
                    {
                      "name": "myscheme",
                      "priority": 1,
                      "template_name": "${ovh_me_installation_template.mytemplate.template_name}"
                    }
        argumentDocs:
            disks: ': Disk List. Syntax is cX:dY for disks and [cX:dY,cX:dY] for groups. With X and Y resp. the controller id and the disk id.'
            id: ': a fake id associated with this partition scheme hardware raid group formatted as follow: template_name/scheme_name/name'
            mode: ': RAID mode (raid0, raid1, raid10, raid5, raid50, raid6, raid60).'
            name: ': Hardware RAID name.'
            scheme_name: ': (Required) The partition scheme name.'
            step: ': Specifies the creation order of the hardware RAID.'
            template_name: ': (Required) The template name of the partition scheme.'
        importStatements: []
    ovh_me_installation_template_partition_scheme_partition:
        subCategory: ""
        name: ovh_me_installation_template_partition_scheme_partition
        title: ""
        examples:
            - name: root
              manifest: |-
                {
                  "filesystem": "ext4",
                  "mountpoint": "/",
                  "order": 1,
                  "scheme_name": "${ovh_me_installation_template_partition_scheme.scheme.name}",
                  "size": "400",
                  "template_name": "${ovh_me_installation_template_partition_scheme.scheme.template_name}",
                  "type": "primary"
                }
              references:
                scheme_name: ovh_me_installation_template_partition_scheme.scheme.name
                template_name: ovh_me_installation_template_partition_scheme.scheme.template_name
              dependencies:
                ovh_me_installation_template.mytemplate: |-
                    {
                      "base_template_name": "centos7_64",
                      "default_language": "fr",
                      "template_name": "mytemplate"
                    }
                ovh_me_installation_template_partition_scheme.scheme: |-
                    {
                      "name": "myscheme",
                      "priority": 1,
                      "template_name": "${ovh_me_installation_template.mytemplate.template_name}"
                    }
        argumentDocs:
            filesystem: ': Partition filesystem. Enum with possibles values:'
            id: ': a fake id associated with this partition scheme partition formatted as follow: template_name/scheme_name/mountpoint'
            mountpoint: ': (Required) partition mount point.'
            order: ': step or order. specifies the creation order of the partition on the disk'
            raid: ': raid partition type. Enum with possible values:'
            scheme_name: ': (Required) The partition scheme name.'
            size: ': size of partition in MB, 0 => rest of the space.'
            template_name: ': (Required) The template name of the partition scheme.'
            type: ': partition type. Enum with possible values:'
            volume_name: ': The volume name needed for proxmox distribution'
        importStatements: []
    ovh_me_ipxe_script:
        subCategory: ""
        name: ovh_me_ipxe_script
        title: ""
        examples:
            - name: script
              manifest: |-
                {
                  "name": "myscript",
                  "script": "${file(\"${path.module}/boot.ipxe\")}"
                }
        argumentDocs:
            description: '- For documentation purpose only. This attribute is not passed to the OVHcloud API as it cannot be retrieved back. Instead a fake description (''$name auto description'') is passed at creation time.'
            name: '- (Required) The name of the IPXE Script.'
            script: '- (Required) The content of the script.'
        importStatements: []
    ovh_me_ssh_key:
        subCategory: ""
        name: ovh_me_ssh_key
        title: ""
        examples:
            - name: mykey
              manifest: |-
                {
                  "key": "ssh-ed25519 AAAAC3...",
                  "key_name": "mykey"
                }
        argumentDocs:
            default: '- True when this public SSH key is used for rescue mode and reinstallations.'
            key: '- (Required) The content of the public key in the form "ssh-algo content", e.g. "ssh-ed25519 AAAAC3...".'
            key_name: '- (Required) The friendly name of this SSH key.'
        importStatements: []
    ovh_vrack:
        subCategory: ""
        name: ovh_vrack
        title: ""
        examples:
            - name: vrack
              manifest: |-
                {
                  "description": "my vrack",
                  "name": "my vrack",
                  "ovh_subsidiary": "${data.ovh_order_cart.mycart.ovh_subsidiary}",
                  "plan": [
                    {
                      "duration": "${data.ovh_order_cart_product_plan.vrack.selected_price.0.duration}",
                      "plan_code": "${data.ovh_order_cart_product_plan.vrack.plan_code}",
                      "pricing_mode": "${data.ovh_order_cart_product_plan.vrack.selected_price.0.pricing_mode}"
                    }
                  ]
                }
              references:
                ovh_subsidiary: data.ovh_order_cart.mycart.ovh_subsidiary
                plan.duration: data.ovh_order_cart_product_plan.vrack.selected_price.0.duration
                plan.plan_code: data.ovh_order_cart_product_plan.vrack.plan_code
                plan.pricing_mode: data.ovh_order_cart_product_plan.vrack.selected_price.0.pricing_mode
        argumentDocs:
            catalog_name: '- Catalog name'
            configuration: '- (Optional) Representation of a configuration item for personalizing product'
            date: '- date'
            description: '- yourvrackdescription'
            details: '- Information about a Bill entry'
            domain: '- expiration date'
            duration: '- (Required) duration'
            expiration_date: '- expiration date'
            label: '- (Required) Identifier of the resource'
            name: '- yourvrackname'
            order: '- Details about an Order'
            order_detail_id: '- order detail id'
            order_id: '- order id'
            ovh_subsidiary: '- (Required) OVHcloud Subsidiary'
            plan: '- (Required) Product Plan to order'
            plan_code: '- (Required) Plan code'
            plan_option: '- (Optional) Product Plan to order'
            pricing_mode: '- (Required) Pricing model identifier'
            quantity: '- quantity'
            service_name: '- The internal name of your vrack'
            value: '- (Required) Path to the resource in API.OVH.COM'
        importStatements: []
    ovh_vrack_cloudproject:
        subCategory: ""
        name: ovh_vrack_cloudproject
        title: ""
        examples:
            - name: vcp
              manifest: |-
                {
                  "project_id": "67890",
                  "service_name": "12345"
                }
        argumentDocs:
            project_id: |-
                - (Required) The id of the public cloud project. If omitted,
                the OVH_CLOUD_PROJECT_SERVICE environment variable is used.
            service_name: |-
                - (Required) The service name of the vrack. If omitted,
                the OVH_VRACK_SERVICE environment variable is used.
        importStatements: []
    ovh_vrack_dedicated_server:
        subCategory: ""
        name: ovh_vrack_dedicated_server
        title: ""
        examples:
            - name: vds
              manifest: |-
                {
                  "server_id": "67890",
                  "service_name": "XXXX"
                }
        argumentDocs:
            server_id: '- (Required) The id of the dedicated server.'
            service_name: |-
                - (Required) The service name of the vrack. If omitted,
                the OVH_VRACK_SERVICE environment variable is used.
        importStatements: []
    ovh_vrack_dedicated_server_interface:
        subCategory: ""
        name: ovh_vrack_dedicated_server_interface
        title: ""
        examples:
            - name: vdsi
              manifest: |-
                {
                  "interface_id": "${data.ovh_dedicated_server.server.enabled_vrack_vnis[0]}",
                  "service_name": "pn-xxxxxxx"
                }
              references:
                interface_id: data.ovh_dedicated_server.server.enabled_vrack_vnis[0]
        argumentDocs:
            interface_id: '- (Required) The id of dedicated server network interface.'
            service_name: |-
                - (Required) The id of the vrack. If omitted,
                the OVH_VRACK_SERVICE environment variable is used.
        importStatements: []
    ovh_vrack_iploadbalancing:
        subCategory: ""
        name: ovh_vrack_iploadbalancing
        title: ""
        examples:
            - name: viplb
              manifest: |-
                {
                  "ip_loadbalancing": "yyy",
                  "service_name": "xxx"
                }
        argumentDocs:
            ip_loadbalancing: '- (Required) The id of the IP Load Balancing.'
            service_name: '- (Required) The id of the vrack.'
        importStatements: []
